{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "<pre></pre>\n",
    "<font size=+1>\n",
    "\n",
    "[Useful Functions](#Useful-Functions)<pre></pre>\n",
    "[Data Prep](#Data-Prep)<pre></pre>\n",
    "[Modeling](#Modeling)<pre></pre>\n",
    "[Linear Regression](#Linear-Regression)<pre></pre>\n",
    "[Validate Linear Regression](#Validate-Linear-Regression)<pre></pre>\n",
    "[Logistic Regression](#Logistic-Regression)<pre></pre>\n",
    "[Validate Logistic Regression](#Validate-Logistic-Regression)<pre></pre>\n",
    "[Random Forest](#Random-Forest)<pre></pre>\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Magnify any Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "def hover(hover_color=\"#ffff99\"):\n",
    "    return dict(selector=\"tr:hover\",\n",
    "                props=[(\"background-color\", \"%s\" % hover_color)])\n",
    "\n",
    "def magnify_df(df):\n",
    "    styles = [\n",
    "    dict(selector=\"th\",props=[(\"font-size\", \"15pt\")]),\n",
    "    dict(selector=\"td\",props=[('padding', \"0em 0em\")]),\n",
    "    dict(selector=\"th:hover\",props=[(\"font-size\", \"15pt\")]),\n",
    "    dict(selector=\"tr:hover td:hover\",props=[('max-width', '200px'),('font-size', '15pt')])\n",
    "    ]\n",
    "    return(df.style.set_table_styles(styles).set_caption(\"Hover to highlight.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Create Correlation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np   \n",
    "sns.set(rc={'figure.figsize':(10,13)}, font_scale = 2)\n",
    "\n",
    "def correlation_plot(df, target_col_name):\n",
    "    corr = df.loc[:, df.columns != target_col_name].corr()\n",
    "    plt.figure(figsize=(20,13))\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    sns.set_context(\"paper\", font_scale=2)\n",
    "    plt.title('Variables of Interest in our Analysis', fontsize=40)\n",
    "    correlation_plot = sns.heatmap(df.loc[:, df.columns != target_col_name].corr(), annot=False, linewidth=.5, cmap=\"coolwarm\", mask=mask)\n",
    "    return correlation_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Create Confusion Matrix Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#This creates confusion matrix visualization\n",
    "import matplotlib.pylab as plt\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False):\n",
    "    plt.figure(figsize = (5,5))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion matrix')\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "[Go back to the Table of Contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subscribed_deposit     0\n",
       "age                    0\n",
       "balance                0\n",
       "duration               0\n",
       "campaign               0\n",
       "previous               0\n",
       "marital_married        0\n",
       "marital_single         0\n",
       "job_blue-collar        0\n",
       "job_entrepreneur       0\n",
       "job_housemaid          0\n",
       "job_management         0\n",
       "job_retired            0\n",
       "job_self-employed      0\n",
       "job_services           0\n",
       "job_student            0\n",
       "job_technician         0\n",
       "job_unemployed         0\n",
       "education_secondary    0\n",
       "education_tertiary     0\n",
       "default_yes            0\n",
       "housing_yes            0\n",
       "loan_yes               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "cleaned_data = pd.read_csv('cleaned_data.csv')\n",
    "cleaned_data.drop('Unnamed: 0', 1, inplace=True)\n",
    "cleaned_data.rename({'y_yes': 'subscribed_deposit'}, axis=1, inplace=True)\n",
    "cleaned_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code For One Hot Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get one hot encoded values for independent categorical variables\n",
    "#merge one hot encoded variables with independent numeric variables\n",
    "\n",
    "# X_enc = pd.get_dummies(df_clean[['marital', 'job', 'education', 'default', 'housing', 'loan', 'y']], drop_first= True)\n",
    "\n",
    "# numeric_data = df_clean[['age', 'balance', 'duration', 'campaign', 'previous']]\n",
    "    \n",
    "# cleaned_data_merge = pd.merge(numeric_data, X_enc, how = 'left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Omitted Categories for one hot encoded variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Marital - Divorced\n",
    "#Jobs - admin\n",
    "#Education - primary\n",
    "#default - no\n",
    "#housing - no\n",
    "#loan - no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "[Go back to the Table of Contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_plot(cleaned_data, 'age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "[Go back to the Table of Contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np \n",
    "import statsmodels.api as sm \n",
    "import pylab as py\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import statistics\n",
    "  \n",
    "\n",
    "def Basic_Linear_Regression(df, target_col_name, test_size):\n",
    "    cleaned_data_y = df.loc[:, cleaned_data.columns == target_col_name]\n",
    "    cleaned_data_x = df.loc[:, cleaned_data.columns != target_col_name]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(cleaned_data_x, cleaned_data_y, test_size=test_size, random_state= 1254)\n",
    "\n",
    "    #Regression RMSE\n",
    "    # Train the model\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = lm.predict(x_test)\n",
    "\n",
    "    # Compute the root-mean-square\n",
    "\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(x_train, y_train)\n",
    "\n",
    "    MSEs = cross_val_score(lm, x_train, y=y_train, scoring='neg_mean_squared_error', cv=int((1/test_size)))\n",
    "    RMSE = (MSEs*-1)**0.5\n",
    "    \n",
    "    print('\\n')\n",
    "    print('Basic Linear Regression Average Training RMSE:')\n",
    "    print('\\n')\n",
    "    print(statistics.mean(RMSE))\n",
    "    print('\\n')\n",
    "    print('RMSE for each Training fold:')\n",
    "    print('\\n')\n",
    "    print(RMSE)\n",
    "    print('\\n')\n",
    "    # Compute the root-mean-square\n",
    "    RMSE_testing = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print('\\n')\n",
    "    print('Basic Linear Regression Tested RMSE Score:')\n",
    "    print('\\n')\n",
    "    print(RMSE_testing)\n",
    "    print('\\n')\n",
    "    \n",
    "    #Regression Model\n",
    "    x_train = sm.add_constant(x_train)# adding a constant\n",
    "    x_test = sm.add_constant(x_test)\n",
    "    model=sm.OLS(y_train, x_train).fit()\n",
    "    print(model.summary())\n",
    "    \n",
    "    pvalues_df = pd.DataFrame(model.pvalues)\n",
    "    pvalues_df.reset_index(inplace=True)\n",
    "    pvalues_df.rename(columns={\"index\": \"Variables\", 0: \"Pvalues\"}, inplace=True)\n",
    "\n",
    "    #Creates new dataframe for all significant variables\n",
    "    df_not_significant = pvalues_df.loc[pvalues_df['Pvalues'] > .05]\n",
    "    df_not_significant['Pvalues'] = df_not_significant['Pvalues'].apply(lambda x: '%.5f' % x)\n",
    "    print('\\n')\n",
    "    print('These Are the Linear Regression Variables That are not significant:')\n",
    "    print('\\n')\n",
    "    print(df_not_significant)\n",
    "    \n",
    "    coefficients_df = pd.DataFrame(model.params)\n",
    "    coefficients_df.reset_index(inplace=True)\n",
    "    coefficients_df.rename(columns={\"index\": \"Variables\", 0: \"Absolute_Coefficients\"}, inplace=True)\n",
    "    coefficients_df['Absolute_Coefficients'] = abs(coefficients_df['Absolute_Coefficients'])\n",
    "    coefficients_df.sort_values(by=[\"Absolute_Coefficients\"], ascending=False, inplace=True)\n",
    "    Feature_Importance = sns.barplot(x=\"Absolute_Coefficients\", y=\"Variables\", data=coefficients_df)\n",
    "    \n",
    "    print('\\n')\n",
    "    print('Figure Showing Relative Variable Coefficients, Remember Some Are Continuous:')\n",
    "    print('\\n')\n",
    "    return Feature_Importance\n",
    "    \n",
    "    \n",
    "    print('\\n')\n",
    "    print('This is a plot of the Regression fitting  Test Data:')\n",
    "    print('\\n')\n",
    "    sns.set(style='ticks')\n",
    "    sns.regplot(y_test, y=y_pred, scatter_kws={'alpha':0.5});\n",
    "    plt.title('Prediction Performance for Age')\n",
    "    plt.ylabel('Age')\n",
    "    plt.xlabel('Trained Regression')\n",
    "    py.show() \n",
    "    \n",
    "    # np.random generates different random numbers \n",
    "    # whenever the code is executed \n",
    "    # Note: When you execute the same code  \n",
    "    # the graph look different than shown below.\n",
    "    \n",
    "    print('\\n')\n",
    "    print('This is a QQplot which tests for a normal distribution of residuals where residuals should follow line:')\n",
    "    print('\\n')\n",
    "    data_points = model.resid\n",
    "    sm.qqplot(data_points, line ='45')\n",
    "    py.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Basic_Linear_Regression(df=cleaned_data, target_col_name='age', test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Linear Regression\n",
    "[Go back to the Table of Contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(10,13)}, font_scale = 2)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "def Linear_Regression_Test(df, target_col_name, numeric_column_list, test_size):\n",
    "\n",
    "    #Split Data into training and testing groups\n",
    "    #We will have to standardize the numeric independent variables    \n",
    "    cleaned_data_y = df.loc[:, df.columns == target_col_name]\n",
    "    cleaned_data_x = df.loc[:, df.columns != target_col_name]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(cleaned_data_x, cleaned_data_y, test_size=test_size, random_state= 1254)\n",
    "\n",
    "    scalar = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "    scalar_x_train_numeric = pd.DataFrame(scalar.fit_transform(x_train[numeric_column_list]), index=x_train[numeric_column_list].index, columns=numeric_column_list)\n",
    "    scalar_x_test_numeric = pd.DataFrame(scalar.transform(x_test[numeric_column_list]), index = x_test.index, columns=numeric_column_list)\n",
    "\n",
    "    #Merge standardized numerical independent variables with categorical independent variables\n",
    "    x_train_complete = pd.merge(scalar_x_train_numeric, x_train[x_train.columns.difference(numeric_column_list)], how = 'left', left_index=True, right_index=True)\n",
    "    x_test_complete = pd.merge(scalar_x_test_numeric, x_test[x_test.columns.difference(numeric_column_list)], how = 'left', left_index=True, right_index=True)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(x_train_complete, y_train)\n",
    "    \n",
    "    lasso_params = {'alpha':np.array([0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000])}\n",
    "    ridge_params = {'alpha':np.array([0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000])}\n",
    "    \n",
    "    Lasso_CV = GridSearchCV(linear_model.Lasso(), \n",
    "                            param_grid=lasso_params, scoring='neg_mean_squared_error', cv=int((1/test_size))).fit(x_train, y_train)\n",
    "    print('Average Training Lasso RMSE Score With best Penalty: ', abs(Lasso_CV.best_score_)**0.5)\n",
    "    print('\\n')\n",
    "\n",
    "    print('Best Lasso Penalty:', Lasso_CV.best_estimator_.get_params()['alpha'])\n",
    "    print('\\n')\n",
    "    \n",
    "    Ridge_CV = GridSearchCV(linear_model.Ridge(), \n",
    "                            param_grid=ridge_params, scoring='neg_mean_squared_error', cv=int((1/test_size))).fit(x_train, y_train)\n",
    "    print('Best Training Ridge RMSE Score With best Penalty: ', abs(Ridge_CV.best_score_)**0.5)\n",
    "    print('\\n')\n",
    "    print('Best Ridge Penalty:', Ridge_CV.best_estimator_.get_params()['alpha'])\n",
    "    print('\\n')\n",
    "    \n",
    "    model_OLS = sm.OLS(y_train, x_train)\n",
    "    results_fu = model_OLS.fit()\n",
    "\n",
    "    results_fr = model_OLS.fit_regularized(L1_wt=1.0, alpha=Lasso_CV.best_estimator_.get_params()['alpha'], start_params=results_fu.params)\n",
    "    results_fr_fit = sm.regression.linear_model.OLSResults(model_OLS, results_fr.params, model_OLS.normalized_cov_params)\n",
    "\n",
    "    final = sm.regression.linear_model.OLSResults(model_OLS, results_fr.params, model_OLS.normalized_cov_params)\n",
    "    print('Best Lasso Results:')\n",
    "    print('\\n')\n",
    "    print(final.summary())\n",
    "\n",
    "    Best_Lasso_Coefficients = pd.DataFrame(final.params)\n",
    "    Best_Lasso_Coefficients.reset_index(inplace=True)\n",
    "    Best_Lasso_Coefficients.rename(columns={\"index\": \"Variables\", 0: \"Coefficients\"}, inplace=True)\n",
    "    Best_Lasso_Coefficients.sort_values(by=[\"Coefficients\"], ascending=False, inplace=True)\n",
    "\n",
    "    Feature_Importance_Lasso = sns.barplot(x=\"Coefficients\", y=\"Variables\", data=Best_Lasso_Coefficients)\n",
    "    return Feature_Importance_Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Lasso Model RMSE, Coefficients, and Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear_Regression_Test(cleaned_data, 'age', ['balance', 'campaign', 'duration'], 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "[Go back to the Table of Contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prints accuracy of normal logistic regression and coefficient values after scaling\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import roc_auc_score, auc, roc_curve, confusion_matrix\n",
    "\n",
    "def Basic_Logistic_Regression(cleaned_data, target_col_name, numeric_column_list, test_size):\n",
    "\n",
    "    #Split Data into training and testing groups\n",
    "    #We will have to standardize the numeric independent variables    \n",
    "    cleaned_data_y = cleaned_data.loc[:, cleaned_data.columns == target_col_name]\n",
    "    cleaned_data_x = cleaned_data.loc[:, cleaned_data.columns != target_col_name]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(cleaned_data_x, cleaned_data_y, test_size=test_size, random_state= 1254)\n",
    "\n",
    "    scalar = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "    scalar_x_train_numeric = pd.DataFrame(scalar.fit_transform(x_train[numeric_column_list]), index=x_train[numeric_column_list].index, columns=numeric_column_list)\n",
    "    scalar_x_test_numeric = pd.DataFrame(scalar.transform(x_test[numeric_column_list]), index = x_test.index, columns=numeric_column_list)\n",
    "\n",
    "    #Merge standardized numerical independent variables with categorical independent variables\n",
    "    x_train_complete = pd.merge(scalar_x_train_numeric, x_train[x_train.columns.difference(numeric_column_list)], how = 'left', left_index=True, right_index=True)\n",
    "    x_test_complete = pd.merge(scalar_x_test_numeric, x_test[x_test.columns.difference(numeric_column_list)], how = 'left', left_index=True, right_index=True)\n",
    "    \n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(x_train_complete, y_train)\n",
    "    y_pred = logreg.predict(x_test_complete)\n",
    "    print('\\n')\n",
    "    print('Accuracy of logistic regression classifier on test set: {:.4f}'.format(logreg.score(x_test_complete, y_test)))\n",
    "    print('\\n')\n",
    "    \n",
    "    model = sm.Logit(y_train, x_train_complete)\n",
    "    result=model.fit()\n",
    "    print('\\n')\n",
    "    print(result.summary())\n",
    "    print('\\n')\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(x_test)[:,1])\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'fpr' : pd.Series(fpr, index=i),'tpr' : pd.Series(tpr, index = i), '1-fpr' : pd.Series(1-fpr, index = i), 'tf' : pd.Series(tpr - (1-fpr), index = i), 'thresholds' : pd.Series(thresholds, index = i)})\n",
    "    roc = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "    print('\\n')\n",
    "    print(roc)\n",
    "    print('\\n')\n",
    "    \n",
    "    pvalues_df = pd.DataFrame(result.pvalues)\n",
    "    pvalues_df.reset_index(inplace=True)\n",
    "    pvalues_df.rename(columns={\"index\": \"Variables\", 0: \"Pvalues\"}, inplace=True)\n",
    "\n",
    "    #Creates new dataframe for all significant variables\n",
    "    df_not_significant = pvalues_df.loc[pvalues_df['Pvalues'] > .05]\n",
    "    df_not_significant['Pvalues'] = df_not_significant['Pvalues'].apply(lambda x: '%.5f' % x)\n",
    "    print('Not Significant Variables:')\n",
    "    print('\\n')\n",
    "    print(df_not_significant)\n",
    "    print('\\n')\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_plot = plot_confusion_matrix(cm, ['0', '1'])\n",
    "    return cm_plot\n",
    "    \n",
    "Basic_Logistic_Regression(cleaned_data, 'subscribed_deposit', ['age','balance', 'campaign', 'duration'], test_size= 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimum Threshhold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Logistic Regression\n",
    "[Go back to the Table of Contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, auc, roc_curve, confusion_matrix\n",
    "\n",
    "def Logistic_Regression_Test(penalty_list, target_col_name, numeric_column_list, test_size):\n",
    "    #Split Data into training and testing groups\n",
    "    #We will have to standardize the numeric independent variables    \n",
    "    cleaned_data_y = cleaned_data.loc[:, cleaned_data.columns == target_col_name]\n",
    "    cleaned_data_x = cleaned_data.loc[:, cleaned_data.columns != target_col_name]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(cleaned_data_x, cleaned_data_y, test_size=test_size, random_state= 1254)\n",
    "\n",
    "    scalar = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "    scalar_x_train_numeric = pd.DataFrame(scalar.fit_transform(x_train[numeric_column_list]), index=x_train[numeric_column_list].index, columns=numeric_column_list)\n",
    "    scalar_x_test_numeric = pd.DataFrame(scalar.transform(x_test[numeric_column_list]), index = x_test.index, columns=numeric_column_list)\n",
    "\n",
    "    #Merge standardized numerical independent variables with categorical independent variables\n",
    "    x_train_complete = pd.merge(scalar_x_train_numeric, x_train[x_train.columns.difference(numeric_column_list)], how = 'left', left_index=True, right_index=True)\n",
    "    x_test_complete = pd.merge(scalar_x_test_numeric, x_test[x_test.columns.difference(numeric_column_list)], how = 'left', left_index=True, right_index=True)\n",
    "\n",
    "    logreg = LogisticRegression()\n",
    "    grid={\"C\":np.array(penalty_list), \"penalty\":[\"l1\"]}\n",
    "    logreg_cv=GridSearchCV(logreg,grid,cv=5)\n",
    "    logreg_cv.fit(x_train,y_train)\n",
    "    \n",
    "    print('The Best Penalty:', logreg_cv.best_estimator_.get_params()['penalty'])\n",
    "    print('The Best C:', logreg_cv.best_estimator_.get_params()['C'])\n",
    "\n",
    "    logreg = LogisticRegression(penalty='l1', C=logreg_cv.best_estimator_.get_params()['C'])\n",
    "    logreg.fit(x_train, y_train)\n",
    "    THRESHOLD = 0.5\n",
    "    preds = np.where(logreg.predict_proba(x_test)[:,1] > THRESHOLD, 1, 0)\n",
    "    print('Accuracy : {:.4f}'.format(accuracy_score(y_test, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_Regression_Test([0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], 'subscribed_deposit', ['age','balance', 'campaign', 'duration'], 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "logreg = LogisticRegression(penalty='l1', C=3)\n",
    "logreg.fit(x_train, y_train)\n",
    "THRESHOLD = 0.47\n",
    "preds = np.where(logreg.predict_proba(x_test)[:,1] > THRESHOLD, 1, 0)\n",
    "print('Accuracy : {:.4f}'.format(accuracy_score(y_test, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test, preds, average='macro')\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_lasso = confusion_matrix(y_test, preds)\n",
    "plot_confusion_matrix(cm_lasso, classes=['0','1'], normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso Prediction Probabilities\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np  \n",
    "   \n",
    "a = logreg.predict_proba(x_test)[:,1]\n",
    "bins = np.arange(0, 1, 0.005).tolist()\n",
    "plt.hist(a, bins)\n",
    "plt.title(\"histogram\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of Lasso Logistic Regression Accuracy at all thresholds\n",
    "\n",
    "accuracy=[]\n",
    "for i in range(0,100):\n",
    "    preds = np.where(logreg.predict_proba(x_test)[:,1] > (0.01 * i), 1, 0)\n",
    "    accuracy.append(accuracy_score(y_test, preds))\n",
    "\n",
    "plt.bar(list(range(0,100)), accuracy, label=\"Threshhold Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "# The following commands add labels to our figure.\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Vertical Bar chart')\n",
    "\n",
    "plt.show()\n",
    "##Highest Accuracy Threshold\n",
    "\n",
    "print('Threshold for highest accuracy:', accuracy.index(max(accuracy)), 'Accuracy:', max(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Highest Accuracy Threshold\n",
    "\n",
    "accuracy.index(max(accuracy)), max(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "[Go back to the Table of Contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8936122857778767\n",
      "[[3911   84]\n",
      " [ 395  103]]\n",
      "precision: 0.7265288816355677\n",
      "recall: 0.6352109313348513\n",
      "fscore: 0.6644647131242306\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# random forest model creation\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train, y_train)\n",
    "# predictions\n",
    "rfc_predict = rfc.predict(x_test)\n",
    "\n",
    "accuracy1 = accuracy_score(y_test, rfc_predict)\n",
    "print(accuracy1)\n",
    "\n",
    "cm2 = confusion_matrix(y_test, clf_predict)\n",
    "print(cm2)\n",
    "\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test, rfc_predict, average='macro')\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "import seaborn as sns\n",
    "\n",
    "def RFC_Feature_Importance(model, x_train, y_train, random_state = 42):\n",
    "    rfc = RandomForestClassifier()\n",
    "    rfc.fit(x_train, y_train)\n",
    "    # predictions\n",
    "    rfc_predict = rfc.predict(x_test)\n",
    "    benchmark_score = model_clone.score(x_train, y_train)\n",
    "    print(benchmark_score)\n",
    "    # list for storing feature importances\n",
    "    importances = []\n",
    "    \n",
    "    # iterating over all columns and storing feature importance (difference between benchmark and new model)\n",
    "    for col in x_train.columns:\n",
    "        model2 = RandomForestClassifier()\n",
    "        model2.fit(x_train.drop(col, axis = 1), y_train)\n",
    "        drop_col_score = model2.score(x_train.drop(col, axis = 1), y_train)\n",
    "        importances.append(benchmark_score - drop_col_score)\n",
    "    \n",
    "    importances_df = pd.DataFrame({'Features': x_train.columns, 'Importance' : importances})\n",
    "    importances_df.sort_values(by= ['Importance'], ascending=False, inplace=True)\n",
    "    importances_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFC_Best_Model(target_col_name, numeric_column_list, test_size, param_grid_dict):\n",
    "    #Split Data into training and testing groups\n",
    "    #We will have to standardize the numeric independent variables    \n",
    "    cleaned_data_y = cleaned_data.loc[:, cleaned_data.columns == target_col_name]\n",
    "    cleaned_data_x = cleaned_data.loc[:, cleaned_data.columns != target_col_name]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(cleaned_data_x, cleaned_data_y, test_size=test_size, random_state= 1254)\n",
    "\n",
    "    scalar = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "    scalar_x_train_numeric = pd.DataFrame(scalar.fit_transform(x_train[numeric_column_list]), index=x_train[numeric_column_list].index, columns=numeric_column_list)\n",
    "    scalar_x_test_numeric = pd.DataFrame(scalar.transform(x_test[numeric_column_list]), index = x_test.index, columns=numeric_column_list)\n",
    "\n",
    "    #Merge standardized numerical independent variables with categorical independent variables\n",
    "    x_train_complete = pd.merge(scalar_x_train_numeric, x_train[x_train.columns.difference(numeric_column_list)], how = 'left', left_index=True, right_index=True)\n",
    "    x_test_complete = pd.merge(scalar_x_test_numeric, x_test[x_test.columns.difference(numeric_column_list)], how = 'left', left_index=True, right_index=True)\n",
    "\n",
    "    clf = GridSearchCV(RandomForestClassifier(), param_grid_dict, cv=2)\n",
    "    clf.fit(x_train_complete, y_train)\n",
    "    clf_predict = clf.predict(x_test_complete)\n",
    "    accuracy = accuracy_score(y_test, clf_predict)               \n",
    "    return clf.best_params_, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 12, 'min_samples_split': 4, 'n_estimators': 500},\n",
       " 0.8945025595370576)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_dict = {\n",
    "    'n_estimators': [100, 500],\n",
    "    'max_depth':[3,7,12],\n",
    "    'min_samples_split': [2, 4]\n",
    "}\n",
    "\n",
    "RFC_Best_Model('subscribed_deposit', ['age','balance', 'campaign', 'duration'], 0.1, param_grid_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
