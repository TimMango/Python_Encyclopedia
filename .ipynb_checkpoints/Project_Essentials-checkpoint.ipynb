{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "<pre></pre>\n",
    "<font size=+1>\n",
    "    \n",
    "[Import Data](#Import-Data)<pre></pre>\n",
    "[Manipulating Data](#Manipulating-Data)<pre></pre>\n",
    "[Merging Dataframes and Groupby](#Merging-Dataframes-and-Groupby)<pre></pre>\n",
    "[Plots](#Plots)<pre></pre>\n",
    "[Imputing Data](#Imputing-Data)<pre></pre>\n",
    "[Modeling](#Modeling)<pre></pre>\n",
    "[Dictionaries Example](#Dictionaries-Example)<pre></pre>\n",
    "[API Requests](#API-Requests)<pre></pre>\n",
    "[Classes and OOP](#Classes-and-OOP)<pre></pre>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "\n",
    "[Go back to the Table of Contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages usually want to upload with display settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 5000)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data with encoding type and explicit column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Csv_File_Name.csv', encoding='Encoding_Type',  names = ['Index', 'Column'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get basic Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check type of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a list of column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check values of a given column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for NA values, education has no missing values\n",
    "df_clean['education'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_fips_sliced_df['Full FIPS'] = string_fips_sliced_df['Full FIPS'].astype(dtype = int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.rename({'y_yes': 'Subscribed_Deposit'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Column_Name'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This shows the percent missing values for each  varialble in a dataframe\n",
    "\n",
    "DF_Percent_Missing = DF_Final_Vars.isna().mean().round(4)\n",
    "\n",
    "#This shows the variables with highest missing percent missing values first\n",
    "\n",
    "DF_Percent_Missing.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changes all cells named 'Cell_ Value' to null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace \"unknown\" values as missing\n",
    "\n",
    "df = df_unclean.replace('unknown', np.NaN, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now check counts of missing values\n",
    "#We decided to drop contact and poutcome from our analysis\n",
    "\n",
    "df_unclean.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New column 1/1000th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to provide more manageable values, 'price was divided by 1000, \n",
    "# converting 'price' to thousands ($)\n",
    "df['price1000'] = df['price']/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates new dataframe for all houses worth less than 1 million dollars\n",
    "\n",
    "df_Mill = df.loc[df['price'] < 1000000]\n",
    "df_Mill.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you have a list of column names you would like to keep (If there are many many variables)\n",
    "#This creates a dataframe of the variables of interest\n",
    "\n",
    "Final_DF = df[List_Of_Kept_Var_Names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform to string take slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Target FIPs codes ready to merge\n",
    "#data type needs to be string for manipulation\n",
    "string_fips = TRI_df['FIPS'].astype(dtype = str)\n",
    "\n",
    "#This reduces fips code to the block group level\n",
    "string_fips_sliced = string_fips.str.slice(0,-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strip Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This removes non numerical values from strings\n",
    "#Cleaned strings are then assigned to float values\n",
    "\n",
    "import re\n",
    "string_money_df = string_money_df.applymap(lambda x: re.sub(r'[^a-zA-Z0-9 -]', '', str(x)))\n",
    "string_money_df_cleaned = string_money_df.astype(dtype=float)\n",
    "string_money_df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop contact and poutcome variables\n",
    "df_clean.drop(df_clean[['contact', 'poutcome']], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows that contain missing values in a specific column\n",
    "\n",
    "adjusted_df = df['Column_With_Missing_Values'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We identify the missing rows from the variable job\n",
    "#these rows were dropped from the entire dataset\n",
    "####Drops all missing rows from job\n",
    "df_clean=df_unclean[df_unclean['job'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Dataframes and Groupby\n",
    "\n",
    "[Go back to the Table of Contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine multiple dataframes into one dataframe with side by side columns\n",
    "\n",
    "Imputed_dataset = pd.concat([imputed_cat_df, imputed_int_df, imputed_numeric_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Two Dataframes\n",
    "\n",
    "#This is dataframe includes target variable and all explanatory variables\n",
    "df_merged = pd.merge(df1, df2,  how='left', left_on='GIDBG', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groupby aggregate on multiple variables\n",
    "\n",
    "#Aggregate vars of interest by merging column and chemical\n",
    "#This gives chemical count for unique latitude and longitudes\n",
    "\n",
    "unique_merging_df = vars_of_interest_df.groupby(['Merging_Column','30. CHEMICAL']).aggregate(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This shows all variables in a dataframe that have a column name from a list\n",
    "#Just another way of doing it\n",
    "\n",
    "DF_Final_Vars.columns[DF_Final_Vars.columns.isin(cat_var_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Dataframe to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.to_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "ax = sns.barplot(x=\"day\", y=\"total_bill\", data=tips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"tip\", y=\"day\", data=tips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x=\"sex\", y=\"total_bill\",\n",
    "                hue=\"smoker\", col=\"time\",\n",
    "                data=tips, kind=\"bar\",\n",
    "                height=4, aspect=.7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "np.random.seed(42)\n",
    "x = np.random.normal(size=1000)\n",
    "plt.hist(x, density=True, bins=30)  # `density=False` would make counts\n",
    "plt.ylabel('Probability')\n",
    "plt.xlabel('Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create data\n",
    "N = 500\n",
    "x = np.random.rand(N)\n",
    "y = np.random.rand(N)\n",
    "colors = (0,0,0)\n",
    "area = np.pi*3\n",
    "\n",
    "# Plot\n",
    "plt.scatter(x, y, s=area, c=colors, alpha=0.5)\n",
    "plt.title('Scatter plot pythonspot.com')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "sns.boxplot(x=tips[\"day\"],y=tips[\"total_bill\"])\n",
    "plt.title(\"blah\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We identify the mode of the education variable\n",
    "df_clean['education'].mode()\n",
    "\n",
    "#We impute the missing values of education with its mode value\n",
    "# fill missing values with mean column values\n",
    "df_clean['education'].replace(to_replace = np.nan, value= 'whatever the mode is', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute categorical variables\n",
    "\n",
    "#This is to calculate median for strings\n",
    "#Scipy for calculating mode\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "#Loop\n",
    "#I'm Here is to show if loop breaks\n",
    "for i in range(0, len(cat_var_df.columns)):\n",
    "        print('im here:', cat_var_df.columns[i])\n",
    "        imputed_cat_df.iloc[:,i].replace(np.NaN, scipy.stats.mode(imputed_cat_df.iloc[:,i], axis=0, nan_policy='raise')[0][0], inplace=True)      \n",
    "#impute mode for categorical vars\n",
    "\n",
    "#check\n",
    "imputed_cat_df.isna().sum()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Integer Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute median for integers\n",
    "imputed_int_df = int_var_df\n",
    "for i in range(0, len(int_var_df.columns)):\n",
    "        imputed_int_df.iloc[:,i].replace(np.NaN, imputed_int_df.iloc[:,i].median(), inplace=True)\n",
    "        \n",
    "#check\n",
    "imputed_int_df.isna().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute mean for numerical vars\n",
    "imputed_numeric_df = numeric_var_df\n",
    "for i in range(0, len(numeric_var_df.columns)):\n",
    "        print('im here:', numeric_var_df.columns[i])\n",
    "        imputed_numeric_df.iloc[:,i].replace(np.NaN, imputed_numeric_df.iloc[:,i].mean(), inplace=True)\n",
    "        \n",
    "##Imputed numerical dataframe\n",
    "\n",
    "#check\n",
    "imputed_numeric_df.isna().sum()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get one hot encoded values for independent categorical variables\n",
    "#merge one hot encoded variables with independent numeric variables\n",
    "\n",
    "X_enc = pd.get_dummies(df_clean[['marital', 'job', 'education', 'default', 'housing', 'loan', 'y']], drop_first= True)\n",
    "\n",
    "numeric_data = df_clean[['age', 'balance', 'duration', 'campaign', 'previous']]\n",
    "    \n",
    "cleaned_data_merge = pd.merge(numeric_data, X_enc, how = 'left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionaries Example\n",
    "[Go back to the Table of Contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a pizza input and dictionary\n",
    "p = int (input (\"Enter the no. of pizzas you want to buy (max 3): \"))\n",
    "t = int (input (\"Enter the toppings you would like in each pizza (max 4): \"))\n",
    "b = 1\n",
    "dict_pizza = {}\n",
    "for _ in range(p):\n",
    "    pizza = \"\"\n",
    "    pizza = str(input(f\"\\nEnter the flavor of Pizza No. {b}: \"))\n",
    "    dict_pizza[pizza] = []\n",
    "    b += 1\n",
    "    c = 1\n",
    "    for _ in range(t):    \n",
    "        topping = str(input(f\"Enter the flavor of Topping No. {c}: \"))\n",
    "        dict_pizza[pizza].append(topping)\n",
    "        c += 1\n",
    "        \n",
    "print(dict_pizza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Final\n",
    "#Here is what your program would look like with all the changes\n",
    "\n",
    "import os\n",
    "\n",
    "available_pizzas = ['margarita', 'pollo', '4cheese', 'bolognese', 'vegetarian']\n",
    "available_toppings = ['mushroom', 'onions', 'green pepper', 'extra cheese']\n",
    "pizza_prices = {'margarita': 5, 'pollo': 7, '4cheese': 6, 'bolognese': 8, 'vegetarian': 6.5}\n",
    "topping_prices = {'mushroom':1, 'onions': 2, 'green pepper':3, 'extra cheese':4}\n",
    "\n",
    "def ShowMenu():\n",
    "    os.system('cls')\n",
    "    print(\"Available Pizzas:\\n\")\n",
    "    print(*available_pizzas,sep = ', ')\n",
    "    print(\"\\n\\nAvailable Topings:\\n\")\n",
    "    print(*available_toppings,sep = ', ')\n",
    "    print('\\n\\n')\n",
    "\n",
    "def TakeOrderInput():\n",
    "    os.system('cls')\n",
    "    print(\"Hi, welcome to our text based pizza ordering\")\n",
    "    ordering = True\n",
    "    while ordering:\n",
    "        os.system('cls')\n",
    "        ShowMenu()\n",
    "        pizza = input(\"Please choose a pizza: \")\n",
    "        if pizza not in available_pizzas:\n",
    "            print(f\"I am sorry, we currently do not have {pizza}\\n.\")\n",
    "            os.system('pause')\n",
    "            continue\n",
    "        topping = input(\"Please choose a topping: \")\n",
    "        if topping not in available_toppings:\n",
    "            print(f\"I am sorry, we currently do not have {topping}\\n.\")\n",
    "            os.system('pause')\n",
    "            continue\n",
    "\n",
    "        print(f\"Final order: {pizza} with topping {topping}: \")\n",
    "        ordering = False\n",
    "\n",
    "    return pizza,topping\n",
    "\n",
    "class Order:\n",
    "    def __init__(self):\n",
    "        taxes = 0 #You can add taxes\n",
    "        pizza,topping = TakeOrderInput()\n",
    "        self.type = pizza\n",
    "        self.topping = topping\n",
    "        self.PizzaPrice = pizza_prices[pizza]\n",
    "        self.ToppingPrice = topping_prices[topping]\n",
    "        self.Total = self.PizzaPrice + self.ToppingPrice\n",
    "\n",
    "\n",
    "choice = True\n",
    "orders = []\n",
    "orderchoice = input(\"Welcome! Would you like to order ? (y/n): \")\n",
    "if orderchoice == 'n':\n",
    "    print(\"Have a nice day!\")\n",
    "else:\n",
    "    while choice:\n",
    "        neworder = Order()\n",
    "        orders.append(neworder)\n",
    "        newchoice = input(\"Would you like to order again? (y/n): \")\n",
    "        if (newchoice) == 'n':\n",
    "            break\n",
    "\n",
    "total = 0\n",
    "for order in orders:\n",
    "    total+=order.Total\n",
    "\n",
    "print(\"Total: \",total, '$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes and OOP\n",
    "[Go back to the Table of Contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student(object):\n",
    "    def __init__(self, name, age, gender, level, grades=None):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "        self.gender = gender\n",
    "        self.level = level\n",
    "        self.grades = grades or {}\n",
    "\n",
    "    def setGrade(self, course, grade):\n",
    "        self.grades[course] = grade\n",
    "\n",
    "    def getGrade(self, course):\n",
    "        return self.grades[course]\n",
    "\n",
    "    def getGPA(self):\n",
    "        return sum(self.grades.values())/len(self.grades)\n",
    "\n",
    "# Define some students\n",
    "john = Student(\"John\", 12, \"male\", 6, {\"math\":3.3})\n",
    "jane = Student(\"Jane\", 12, \"female\", 6, {\"math\":3.5})\n",
    "\n",
    "# Now we can get to the grades easily\n",
    "print(john.getGPA())\n",
    "print(jane.getGPA())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class Inheritance\n",
    "\n",
    "# parent class\n",
    "class Bird:\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"Bird is ready\")\n",
    "\n",
    "    def whoisThis(self):\n",
    "        print(\"Bird\")\n",
    "\n",
    "    def swim(self):\n",
    "        print(\"Swim faster\")\n",
    "\n",
    "# child class\n",
    "class Penguin(Bird):\n",
    "\n",
    "    def __init__(self):\n",
    "        # call super() function\n",
    "        super().__init__()\n",
    "        print(\"Penguin is ready\")\n",
    "\n",
    "    def whoisThis(self):\n",
    "        print(\"Penguin\")\n",
    "\n",
    "    def run(self):\n",
    "        print(\"Run faster\")\n",
    "\n",
    "peggy = Penguin()\n",
    "peggy.whoisThis()\n",
    "peggy.swim()\n",
    "peggy.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    '''\n",
    "    Creating Dictionaries with string as key and int as value\n",
    "    '''                                  \n",
    "    wordFrequency = {\n",
    "        \"Hello\" : 7,\n",
    "        \"hi\" : 10,\n",
    "        \"there\" : 45,\n",
    "        \"at\" : 23,\n",
    "        \"this\" : 77\n",
    "        }\n",
    "    '''\n",
    "    Iterate over the dictionary using for loop\n",
    "    '''\n",
    "    for key in wordFrequency:\n",
    "        value = wordFrequency[key]\n",
    "        print(key, \" :: \", value)\n",
    "    \n",
    "    print(\"**************\")    \n",
    "    \n",
    "    '''\n",
    "    Iterate over the dictionary using items()\n",
    "    '''    \n",
    "    for key , value in wordFrequency.items():\n",
    "        print(key, \" :: \", value)    \n",
    "    # Take a dictionary view \n",
    "    dictView =  wordFrequency.items()\n",
    "    \n",
    "    print(\"Dictionary View before modification : \", dictView, sep =\"\\n\")\n",
    "    \n",
    "    # Modify the dictionary\n",
    "    wordFrequency[\"hi\"] = 90\n",
    "    \n",
    "    print(\"Dictionary View after modification : \", dictView, sep =\"\\n\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Requests\n",
    "[Go back to the Table of Contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull request from an API example\n",
    "\n",
    "import requests\n",
    "\n",
    "url = 'https://geo.fcc.gov/api/census/block/find'\n",
    "parameters = {\"lat\": latitude_longitude_df['12. LATITUDE'][0], \"lon\": latitude_longitude_df['13. LONGITUDE'][0], 'showall':'false'}\n",
    "req = requests.get(url, parameters)\n",
    "\n",
    "print(req.status_code)\n",
    "print(req.headers)\n",
    "print(req.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This loop Will pull requests for any set of latitudes and longitudes\n",
    "#Change the length of the loop to go through an entire dataframe\n",
    "#This loop saves a file every 5000 requests\n",
    "#File Names will be labeled like this'FIPs' + '_' + str(count) + '.csv'\n",
    "#Files are updated and overwritten every time the loop is run\n",
    "#If there is an error in the loop SAVE PROGRESS TO A DIFFERENT FILE NAME\n",
    "\n",
    "import requests\n",
    "import datetime\n",
    "\n",
    "latitude_list = []\n",
    "longitude_list = []\n",
    "fips_code_list = []\n",
    "timestamps_list = []\n",
    "count = 0 \n",
    "url = 'https://geo.fcc.gov/api/census/block/find'\n",
    "for i in range(0, 5000):\n",
    "    parameters = {\"lat\": latitude_longitude_df['12. LATITUDE'][i], \"lon\": latitude_longitude_df['13. LONGITUDE'][i], 'showall':'false'}\n",
    "    try:\n",
    "        response = requests.get(url, parameters)\n",
    "        data = response.json()        \n",
    "        latitude_list.append(latitude_longitude_df['12. LATITUDE'][i])\n",
    "        longitude_list.append(latitude_longitude_df['13. LONGITUDE'][i])\n",
    "        fips_code_list.append(data['results'][0]['block_fips'])\n",
    "        timestamps_list.append(datetime.datetime.utcnow())\n",
    "    except:\n",
    "        print('Error at index:', i)\n",
    "        fips_code_list.append('Error')\n",
    "    if ((len(fips_code_list) % 5000) == 0):\n",
    "        FIPs_API_df = pd.DataFrame({'Latitude': latitude_list, 'Longitude': longitude_list, 'FIPS': fips_code_list, 'API_Time': timestamps_list})\n",
    "        pd.DataFrame.to_csv(FIPs_API_df, 'FIPs' + '_' + str(count) + '.csv')\n",
    "        count += 1\n",
    "        \n",
    "FIPs_API_df = pd.DataFrame({'Latitude': latitude_list, 'Longitude': longitude_list, 'FIPS': fips_code_list, 'API_Time': timestamps_list})\n",
    "FIPs_API_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
