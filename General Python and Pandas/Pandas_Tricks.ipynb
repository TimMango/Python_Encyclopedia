{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to this Kernel\n",
    "\n",
    "***This kernel is a compilation of tricks of pandas published by Kevin Markham weekly.***\n",
    "\n",
    "You can find the the original 100 pandas tricks (created by [Kevin Markham](https://www.linkedin.com/in/justmarkham/) from Data School) on this page: \n",
    "\n",
    "https://www.dataschool.io/python-pandas-tips-and-tricks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "[Importing libraries and setting some helper functions](#Imports)\n",
    "    \n",
    "[Trick 1: Add a prefix or suffix to all columns](#trick1)\n",
    "\n",
    "[Trick 2: Reverse order of a df](#trick2)\n",
    "\n",
    "[Trick 3: Filter a df by multiple conditions (isin and inverse using ~)](#trick3)\n",
    "\n",
    "[Trick 4: Select columns by dtype](#trick4)\n",
    "\n",
    "[Trick 5: Convert numbers stored as strings (coerce)](#trick5)\n",
    "\n",
    "[Trick 6: Split a df into 2 random subsets](#trick6)\n",
    "\n",
    "[Trick 7: Dealing with missing values (NaN)](#trick7)\n",
    "\n",
    "[Trick 8: Using glob to generate a df from multiple files !!!duplicated Trick 78!!!](#trick8)\n",
    "\n",
    "[Trick 9: Reduce memory usage of a df while importing](#trick9)\n",
    "\n",
    "[Trick 10: Check the equality of 2 series](#trick10)\n",
    "\n",
    "[Trick 11: Rename all columns with the same pattern](#trick11)\n",
    "\n",
    "[Trick 12: Merging datasets and check uniqueness](#trick12)\n",
    "\n",
    "[Trick 13: Avoid the series of lists TRAP](#trick13)\n",
    "\n",
    "[Trick 14: Creating toy df (3 methods)](#trick14)\n",
    "\n",
    "[Trick 15: Reshape a MultiIndex df (unstack())](#trick15)\n",
    "\n",
    "[Trick 16: Convert continuos values to categorical (cut())](#trick16)\n",
    "\n",
    "[Trick 17: Select multiple rows/columns with loc](#trick17)\n",
    "\n",
    "[Trick 18: Read and write to a compressed file (csv.zip)](#trick18)\n",
    "\n",
    "[Trick 19: Show memory usage of a df and every column](#trick19)\n",
    "\n",
    "[Trick 20: Create a datetime columns from multiple columns](#trick20)\n",
    "\n",
    "[Trick 21: Split a string column into multiple columns](#trick21)\n",
    "\n",
    "[Trick 22: Create DataFrames for testing](#trick22)\n",
    "\n",
    "[Trick 23: Fill missing values in time series data (interpolate())](#trick23)\n",
    "\n",
    "[Trick 24: Copy data from Excel into pandas quick (read_clipboard())](#trick24)\n",
    "\n",
    "[Trick 25: 3 ways of renaming columns names](#trick25)\n",
    "\n",
    "[Trick 26: Formatting different columns of a df (using dictionaries)](#trick26)\n",
    "\n",
    "[Trick 27: Aggregation over timeseries (resample)](#trick27)\n",
    "\n",
    "[Trick 28: Aggregating by multiple columns (using agg)](#trick28)\n",
    "\n",
    "[Trick 29: Access numpy within pandas (without importing numpy as np)](#trick29)\n",
    "\n",
    "[Trick 30: Pandas merge --> see where the columns are coming from (indicator = True)](#trick30)\n",
    "\n",
    "[Trick 31: See all the columns of a big df](#trick31)\n",
    "\n",
    "[Trick 32: Filter a df with query and avoid intermediate variables](#trick32)\n",
    "\n",
    "[Trick 33: Pandas display options](#trick33)\n",
    "\n",
    "[Trick 34: Explore a dataset with profiling](#trick34)\n",
    "\n",
    "[Trick 35: Query a column that has spaces in the name (using backticks)](#trick35)\n",
    "\n",
    "[Trick 36: Convert from UTC to another timezone](#trick36)\n",
    "\n",
    "[Trick 37: Pandas slicing loc and iloc (6 examples)](#trick37)\n",
    "\n",
    "[Trick 38: Pandas datetime (lot's of examples)](#trick38)\n",
    "\n",
    "[Trick 39: One hot encoding (get_dummies())](#trick39)\n",
    "\n",
    "[Trick 40: Style you df fast with hide_index() and set_caption()](#trick40)\n",
    "\n",
    "[Trick 41: Ordered categories (from pandas.api.types import CategoricalDtypee)](#trick41)\n",
    "\n",
    "[Trick 42: New aggregation function --> last()](#trick42)\n",
    "\n",
    "[Trick 43: Create one row for each item in a list (explode) !!!duplicated Trick 47!!!](#trick43)\n",
    "\n",
    "[Trick 44: Use a local variable within a query in pandas (using @)](#trick44)\n",
    "\n",
    "[Trick 45: Create rows for values separated by commas in a cell (assing and explode)](#trick45)\n",
    "\n",
    "[Trick 46: Store NaN in an integer type with Int64](#trick46)\n",
    "\n",
    "[Trick 47: Create one row for each item in a list (explode)](#trick47)\n",
    "\n",
    "[Trick 48: Useful parameters when using pd.read_csv()](#trick48)\n",
    "\n",
    "[Trick 49: Sampling with pandas (with replacement and weights)](#trick49)\n",
    "\n",
    "[Trick 50: Named aggregation with multiple columns passing tupples (new in pandas 0.25)](#trick50)\n",
    "\n",
    "[Trick 51: Concatenate 2 column strings](#trick51)\n",
    "\n",
    "[Trick 52: Making plots with pandas](#trick52)\n",
    "\n",
    "[Trick 53: Shuffle rows of a df (df.sample())](#trick53)\n",
    "\n",
    "[Trick 54: Calculate the difference between each row and the previous (diff())](#trick54)\n",
    "\n",
    "[Trick 55: Filtering a df with multiple criteria using reduce](#trick55)\n",
    "\n",
    "[Trick 56: Apply a mappings to the whole df (applymap)](#trick56)\n",
    "\n",
    "[Trick 57: Accesing the groups of a groupby object (get_group())](#trick57)\n",
    "\n",
    "[Trick 58: Use header and skiprows to get rid of bad data or empty rows while importing](#trick58)\n",
    "\n",
    "[Trick 59: Combine the output of an aggregation with the original df using transform](#trick59)\n",
    "\n",
    "[Trick 60: Creating running totals with cumsum function](#trick60)\n",
    "\n",
    "[Trick 61: Reading JSON from the web into a df](#trick61)\n",
    "\n",
    "[Trick 62: Fixing \"SettingWithCopyWarning\" when changing columns using loc](#trick62)\n",
    "\n",
    "[Trick 63: Calculate running count with groups using cumcount() + 1](#trick63)\n",
    "\n",
    "[Trick 64: Fixing \"SettingWithCopyWarning\" when creating a new columns](#trick64)\n",
    "\n",
    "[Trick 65: Select columns using f-strings (new in pandas 3.6+)](#trick65)\n",
    "\n",
    "[Trick 66: Create a bunch of new columns using a for loop and f-strings df[f'{col}_new']](#trick66)\n",
    "\n",
    "[Trick 67: Create new columns or overwrite using assing](#trick67)\n",
    "\n",
    "[Trick 68: Webscraping using read_html()](#trick68)\n",
    "\n",
    "[Trick 69: Check if 2 series are \"similar\"](#trick69)\n",
    "\n",
    "[Trick 70: Print current version of pandas and it's dependencies](#trick70)\n",
    "\n",
    "[Trick 71: Read data from a PDF (tabula py)](#trick71)\n",
    "\n",
    "[Trick 72: Convert continuos variable to categorical](#trick72)\n",
    "\n",
    "[Trick 73: Remove a column and store it as a separate series](#trick73)\n",
    "\n",
    "[Trick 74: Webscraping using read_html() and match parameter](#trick74)\n",
    "\n",
    "[Trick 75: Count the number of words in a pandas series](#trick75)\n",
    "\n",
    "[Trick 76: Filter in pandas only the largest categories.](#trick76)\n",
    "\n",
    "[Trick 77: Combine the small categories into a single category named \"Others\" (using where)](#trick77)\n",
    "\n",
    "[Trick 78: Keep track of where your data is coming when you are using multiple sources](#trick78)\n",
    "\n",
    "[Trick 79: Count of rows that match a condition](#trick79)\n",
    "\n",
    "[Trick 80: Select multiple slices of columns from a df](#trick80)\n",
    "\n",
    "[Trick 81: Use apply(type) to see if you have mixed data types](#trick81)\n",
    "\n",
    "[Trick 82: Select data by label and position (chained iloc and loc)](#trick82)\n",
    "\n",
    "[Trick 83: Correct the data types while importing the df](#trick83)\n",
    "\n",
    "[Trick 84: Show fewer rows in a df](#trick84)\n",
    "\n",
    "[Trick 85: Convert one type of values to others](#trick85)\n",
    "\n",
    "[Trick 86bis: Named aggregations on multiple columns- avoids multiindex](#trick86bis)\n",
    "\n",
    "[Trick 86: Named aggregations - avoids multiindex](#trick86)\n",
    "\n",
    "[Trick 87: Aggregate you datetime by by and filter weekends](#trick87)\n",
    "\n",
    "[Trick 88: Rearange columns in a DF](#trick88)\n",
    "\n",
    "[Trick 89: Split names into first and last name](#trick89)\n",
    "\n",
    "[Trick 90: Moving columns to a specific location](#trick90)\n",
    "\n",
    "[Trick 91: Creating a time series dataset for testing](#trick91)\n",
    "\n",
    "[Trick 92: Clean Object column with mixed data using regex](#trick92)\n",
    "\n",
    "[Trick 93: Combine the small categories into a single category named \"Others\" (using frequencies)](#trick93)\n",
    "\n",
    "[Trick 94: Save memory by fixing your datetypes](#trick94)\n",
    "\n",
    "[Trick 95: Count the missing values](#trick95)\n",
    "\n",
    "[Trick 96: Interactive plots out of the box in pandas](#trick96)\n",
    "\n",
    "[Trick 97: Convert year and day of year into a single datetime column](#trick97)\n",
    "\n",
    "[Trick 98: Convert a wide DF into a long one](#trick98)\n",
    "\n",
    "[Trick 99: How to avoid Unnamed: 0 columns](#trick99)\n",
    "\n",
    "[Trick 100: Loading sample of a big data file](#trick100)\n",
    "\n",
    "[Importing libraries and setting some helper functions](#Imports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# basic libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# this will allow us to print all the files as we generate more in the kernel\n",
    "def print_files():\n",
    "    for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "        for filename in filenames:\n",
    "            print(os.path.join(dirname, filename))\n",
    "\n",
    "# check Trick 91 for an example\n",
    "def generate_sample_data(): # creates a fake df for testing\n",
    "    number_or_rows = 20\n",
    "    num_cols = 7\n",
    "    cols = list(\"ABCDEFG\")\n",
    "    df = pd.DataFrame(np.random.randint(1, 20, size = (number_or_rows, num_cols)), columns=cols)\n",
    "    df.index = pd.util.testing.makeIntIndex(number_or_rows)\n",
    "    return df\n",
    "\n",
    "# check Trick 91 for an example\n",
    "def generate_sample_data_datetime(): # creates a fake df for testing\n",
    "    number_or_rows = 365*24\n",
    "    num_cols = 2\n",
    "    cols = [\"sales\", \"customers\"]\n",
    "    df = pd.DataFrame(np.random.randint(1, 20, size = (number_or_rows, num_cols)), columns=cols)\n",
    "    df.index = pd.util.testing.makeDateIndex(number_or_rows, freq=\"H\")\n",
    "    return df\n",
    "\n",
    "# show several prints in one cell. This will allow us to condence every trick in one cell.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "print_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"Imports\"></a>\n",
    "# Importing libraries and setting some helper functions\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick1\"></a>\n",
    "# Trick 1: Add a prefix or suffix to all columns\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B   C   D   E   F   G\n",
       "0  19   9  19   6  16  12   3\n",
       "1  16  18   3   5  10   6  10\n",
       "2  13  13  11   5   3  16  17\n",
       "3   3  18  13   2  13   6  17\n",
       "4   8  19   2  12  19  14  15"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add prefix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_A</th>\n",
       "      <th>1_B</th>\n",
       "      <th>1_C</th>\n",
       "      <th>1_D</th>\n",
       "      <th>1_E</th>\n",
       "      <th>1_F</th>\n",
       "      <th>1_G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1_A  1_B  1_C  1_D  1_E  1_F  1_G\n",
       "0   19    9   19    6   16   12    3\n",
       "1   16   18    3    5   10    6   10\n",
       "2   13   13   11    5    3   16   17\n",
       "3    3   18   13    2   13    6   17\n",
       "4    8   19    2   12   19   14   15"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add suffix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_Z</th>\n",
       "      <th>B_Z</th>\n",
       "      <th>C_Z</th>\n",
       "      <th>D_Z</th>\n",
       "      <th>E_Z</th>\n",
       "      <th>F_Z</th>\n",
       "      <th>G_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A_Z  B_Z  C_Z  D_Z  E_Z  F_Z  G_Z\n",
       "0   19    9   19    6   16   12    3\n",
       "1   16   18    3    5   10    6   10\n",
       "2   13   13   11    5    3   16   17\n",
       "3    3   18   13    2   13    6   17\n",
       "4    8   19    2   12   19   14   15"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = generate_sample_data()[:5]\n",
    "print(\"Original df\")\n",
    "df\n",
    "\n",
    "print(\"Add prefix\")\n",
    "df.add_prefix(\"1_\")\n",
    "\n",
    "print(\"Add suffix\")\n",
    "df.add_suffix(\"_Z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick2\"></a>\n",
    "# Trick 2: Reverse order of a df\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B   C   D   E   F   G\n",
       "0   4  16  13   7  10  10   3\n",
       "1  10   8   4  12   3   6  10\n",
       "2  19  14   3  15  12  12  17\n",
       "3  17   8   5  11  11  13  14\n",
       "4  11  13  13  14  12  10  17"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reverse column order\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G</th>\n",
       "      <th>F</th>\n",
       "      <th>E</th>\n",
       "      <th>D</th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    G   F   E   D   C   B   A\n",
       "0   3  10  10   7  13  16   4\n",
       "1  10   6   3  12   4   8  10\n",
       "2  17  12  12  15   3  14  19\n",
       "3  14  13  11  11   5   8  17\n",
       "4  17  10  12  14  13  13  11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reverse row order\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B   C   D   E   F   G\n",
       "4  11  13  13  14  12  10  17\n",
       "3  17   8   5  11  11  13  14\n",
       "2  19  14   3  15  12  12  17\n",
       "1  10   8   4  12   3   6  10\n",
       "0   4  16  13   7  10  10   3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reverse row order and reset index\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B   C   D   E   F   G\n",
       "0  11  13  13  14  12  10  17\n",
       "1  17   8   5  11  11  13  14\n",
       "2  19  14   3  15  12  12  17\n",
       "3  10   8   4  12   3   6  10\n",
       "4   4  16  13   7  10  10   3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = generate_sample_data()[:5]\n",
    "df\n",
    "\n",
    "print(\"Reverse column order\")\n",
    "df.loc[:, ::-1]\n",
    "\n",
    "print(\"Reverse row order\")\n",
    "df.loc[::-1]\n",
    "\n",
    "print(\"Reverse row order and reset index\")\n",
    "df.loc[::-1].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick3\"></a>\n",
    "# Trick 3: Filter a df by multiple conditions (isin and inverse using ~)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter using multiple |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A   B   C   D  E   F  G\n",
       "0  1   2  14  19  1  10  2\n",
       "2  3  11  16   6  5   7  4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter using isin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A   B   C   D  E   F  G\n",
       "0  1   2  14  19  1  10  2\n",
       "2  3  11  16   6  5   7  4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invert using ~ (ctrl + alt + 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A   B  C   D  E   F   G\n",
       "1  2   3  8   6  5   8   1\n",
       "3  4   9  7  13  3   4  10\n",
       "4  5  19  2  10  2  13  12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = generate_sample_data()[:5]\n",
    "df[\"A\"] = [1, 2, 3, 4, 5]\n",
    "\n",
    "print(\"Filter using multiple |\")\n",
    "df[(df[\"A\"] == 1) | (df[\"A\"] == 3)]\n",
    "\n",
    "print(\"Filter using isin\")\n",
    "df[df[\"A\"].isin([1, 3])]\n",
    "\n",
    "print(\"Invert using ~ (ctrl + alt + 4)\")\n",
    "df[~df[\"A\"].isin([1, 3])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick4\"></a>\n",
    "# Trick 4: Select columns by dtype\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sales</th>\n",
       "      <th>customers</th>\n",
       "      <th>string_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-01 01:00:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-01 02:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-01 03:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-01 04:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000-01-01 05:00:00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000-01-01 06:00:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000-01-01 07:00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000-01-01 08:00:00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000-01-01 09:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                index  sales  customers string_col\n",
       "0 2000-01-01 00:00:00    9.0          4          A\n",
       "1 2000-01-01 01:00:00   15.0          7          B\n",
       "2 2000-01-01 02:00:00    4.0         13          C\n",
       "3 2000-01-01 03:00:00    1.0         19          D\n",
       "4 2000-01-01 04:00:00    4.0          7          E\n",
       "5 2000-01-01 05:00:00   12.0          2          A\n",
       "6 2000-01-01 06:00:00   15.0          2          B\n",
       "7 2000-01-01 07:00:00    8.0          6          C\n",
       "8 2000-01-01 08:00:00   19.0          2          D\n",
       "9 2000-01-01 09:00:00    4.0         11          E"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select numerical columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "      <th>customers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales  customers\n",
       "0    9.0          4\n",
       "1   15.0          7\n",
       "2    4.0         13\n",
       "3    1.0         19\n",
       "4    4.0          7\n",
       "5   12.0          2\n",
       "6   15.0          2\n",
       "7    8.0          6\n",
       "8   19.0          2\n",
       "9    4.0         11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select string columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  string_col\n",
       "0          A\n",
       "1          B\n",
       "2          C\n",
       "3          D\n",
       "4          E\n",
       "5          A\n",
       "6          B\n",
       "7          C\n",
       "8          D\n",
       "9          E"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select datetime columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000-01-01 05:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000-01-01 06:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000-01-01 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000-01-01 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000-01-01 09:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                index\n",
       "0 2000-01-01 00:00:00\n",
       "1 2000-01-01 01:00:00\n",
       "2 2000-01-01 02:00:00\n",
       "3 2000-01-01 03:00:00\n",
       "4 2000-01-01 04:00:00\n",
       "5 2000-01-01 05:00:00\n",
       "6 2000-01-01 06:00:00\n",
       "7 2000-01-01 07:00:00\n",
       "8 2000-01-01 08:00:00\n",
       "9 2000-01-01 09:00:00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select miscelaneous\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sales</th>\n",
       "      <th>customers</th>\n",
       "      <th>string_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-01 01:00:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>7</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-01 02:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-01 03:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-01 04:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000-01-01 05:00:00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2000-01-01 06:00:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2000-01-01 07:00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2000-01-01 08:00:00</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000-01-01 09:00:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                index  sales  customers string_col\n",
       "0 2000-01-01 00:00:00    9.0          4          A\n",
       "1 2000-01-01 01:00:00   15.0          7          B\n",
       "2 2000-01-01 02:00:00    4.0         13          C\n",
       "3 2000-01-01 03:00:00    1.0         19          D\n",
       "4 2000-01-01 04:00:00    4.0          7          E\n",
       "5 2000-01-01 05:00:00   12.0          2          A\n",
       "6 2000-01-01 06:00:00   15.0          2          B\n",
       "7 2000-01-01 07:00:00    8.0          6          C\n",
       "8 2000-01-01 08:00:00   19.0          2          D\n",
       "9 2000-01-01 09:00:00    4.0         11          E"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select by passing the dtypes you need\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "      <th>customers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales  customers\n",
       "0    9.0          4\n",
       "1   15.0          7\n",
       "2    4.0         13\n",
       "3    1.0         19\n",
       "4    4.0          7\n",
       "5   12.0          2\n",
       "6   15.0          2\n",
       "7    8.0          6\n",
       "8   19.0          2\n",
       "9    4.0         11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = generate_sample_data_datetime()[:10].reset_index()\n",
    "df[\"string_col\"] = list(\"ABCDEABCDE\")\n",
    "df[\"sales\"] = df[\"sales\"].astype(\"float\")\n",
    "print(\"Original df\")\n",
    "df\n",
    "\n",
    "print(\"Select numerical columns\")\n",
    "df.select_dtypes(include = \"number\")\n",
    "\n",
    "print(\"Select string columns\")\n",
    "df.select_dtypes(include = \"object\")\n",
    "\n",
    "print(\"Select datetime columns\")\n",
    "df.select_dtypes(include = [\"datetime\", \"timedelta\"])\n",
    "\n",
    "print(\"Select miscelaneous\")\n",
    "df.select_dtypes(include = [\"number\", \"object\", \"datetime\", \"timedelta\"])\n",
    "\n",
    "print(\"Select by passing the dtypes you need\")\n",
    "df.select_dtypes(include = [\"int8\", \"int16\", \"int32\", \"int64\", \"float\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick5\"></a>\n",
    "# Trick 5: Convert numbers stored as strings (coerce)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"col1\":[\"1\", \"2\", \"3\", \"stuff\"], \"col2\":[\"1\", \"2\", \"3\", \"4\"]}\n",
    "df = pd.DataFrame(d)\n",
    "df.astype({\"col2\":\"int\"}) # this will fail for col1 --> ValueError: invalid literal for int() with base 10: 'stuff'\n",
    "\n",
    "print(\"Notice that now stuff got converted to NaN\")\n",
    "df.apply(pd.to_numeric, errors = \"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick6\"></a>\n",
    "# Trick 6: Split a df into 2 random subsets\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_sample_data()\n",
    "df_1 = df.sample(frac = 0.7)\n",
    "df_2 = df.drop(df_1.index) # only works if the df index is unique\n",
    "\n",
    "df.shape\n",
    "df_1.shape\n",
    "df_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick7\"></a>\n",
    "# Trick 7: Dealing with missing values (NaN)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.util.testing.makeMissingDataframe().reset_index() # contains missing values\n",
    "df.rename(columns = {\"index\":\"A\"})\n",
    "df1 = df.copy(deep = True)\n",
    "df\n",
    "\n",
    "print(\"Calculate the % of missing values in each row\")\n",
    "df.isna().mean() # calculate the % of missing values in each row\n",
    "print(\"Droping any columns that have missing values. Only column A wil remain\")\n",
    "df.dropna(axis = \"columns\") # drop any column that has missing values\n",
    "print(\"Droping any rows that have missing values.\")\n",
    "df1.dropna(axis = \"rows\") # drop any row that has missing values\n",
    "print(\"Droping column where missing values are above a threshold\")\n",
    "df.dropna(thresh = len(df)*0.95, axis = \"columns\") # drop any row that has missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick8\"></a>\n",
    "# Trick 8: Using glob to generate a df from multiple files !!!duplicated Trick 78!!!\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's generate some fake data\n",
    "df1 = generate_sample_data()\n",
    "df2 = generate_sample_data()\n",
    "df3 = generate_sample_data()\n",
    "# df1.head()\n",
    "# df2.head()\n",
    "# df3.head()\n",
    "df1.to_csv(\"trick8data1.csv\", index = False)\n",
    "df2.to_csv(\"trick8data2.csv\", index = False)\n",
    "df3.to_csv(\"trick8data3.csv\", index = False)\n",
    "\n",
    "# Step 1 generate list with the file name\n",
    "lf = []\n",
    "for _,_, files in os.walk(\"/kaggle/working/\"):\n",
    "    for f in files:\n",
    "        if \"trick8data\" in f:\n",
    "            lf.append(f)\n",
    "            \n",
    "lf\n",
    "\n",
    "# You can use this on your local machine\n",
    "#from glob import glob\n",
    "#files = glob(\"trick8.csv\")\n",
    "\n",
    "# Step 2: we do the same as in trick 78 except we don't create a new column of the rows origin (file they came from)\n",
    "df = pd.concat((pd.read_csv(file) for file in lf), ignore_index = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick9\"></a>\n",
    "# Trick 9: Reduce memory usage of a df while importing !!!duplicated Trick 83!!!\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_files()\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/imdb-data/IMDB-Movie-Data.csv\", \\\n",
    "                 usecols = [\"Title\", \"Genre\", \"Year\", \"Metascore\", \"Revenue (Millions)\"])\n",
    "df.dtypes\n",
    "df.memory_usage(deep = True)\n",
    "\n",
    "print(\"Importing only a few columns and converting to proper dtype\")\n",
    "df = pd.read_csv(\"/kaggle/input/imdb-data/IMDB-Movie-Data.csv\", \\\n",
    "                 usecols = [\"Title\", \"Genre\", \"Year\", \"Metascore\", \"Revenue (Millions)\"], \\\n",
    "                dtype = {\"Genre\":\"category\", \"Metascore\":\"Int64\", \"Year\":\"int8\"})\n",
    "df.dtypes\n",
    "df.memory_usage(deep = True) # notice how Genre and Year are consuming now less memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick10\"></a>\n",
    "# Trick 10: Check the equality of 2 series\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_sample_data()[[\"A\", \"B\"]][:5]\n",
    "df[\"A\"] = pd.Series([15, 15, 18, np.nan, 12])\n",
    "df[\"B\"] = pd.Series([15, 15, 18, np.nan, 12])\n",
    "df\n",
    "\n",
    "print(\"Don't use ==, it does not handle NaN properly\")\n",
    "print(\"Notice that element 4 of each list is np.nan but == still returns False\")\n",
    "df[\"A\"] == df[\"B\"]\n",
    "\n",
    "print(\"Using equals. Now we get True, so the 2 series are equal\")\n",
    "df[\"A\"].equals(df[\"B\"])\n",
    "\n",
    "print(\"Equals also works for df\")\n",
    "df1 = df.copy(deep = True)\n",
    "df.equals(df1)\n",
    "\n",
    "print(\"== of df has the same issue as for series\")\n",
    "df == df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick11\"></a>\n",
    "# Trick 11: Rename all columns with the same pattern\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_files()\n",
    "df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "df.columns = [\"Passenger ID\", \"Survived\", \"Pclass\", \"Name         \", \"Sex\", \"Age\", \"Sib SP\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\"] # creating column names for the example\n",
    "df\n",
    "df1 = df.copy(deep = True)\n",
    "\n",
    "print(\"Replace all spaces with undescore and convert to lower\")\n",
    "print(\"Notice the Passenger and Sib SP column now has underscore\")\n",
    "df.columns = df.columns.str.replace(\" \", \"_\").str.lower()\n",
    "df.head()\n",
    "\n",
    "print(\"Remove trailing (at the end) whitesapce and convert to lower\")\n",
    "print(\"Notice the Passenger and Sib SP column now has underscore\")\n",
    "df1.columns = df1.columns.str.lower().str.rstrip()\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick12\"></a>\n",
    "# Trick 12: Merging datasets and check uniqueness\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_sample_data()[:10]\n",
    "df1 = df.copy(deep = True)\n",
    "df = df.drop([0, 1, 2])\n",
    "df1 = df1.drop([8, 9])\n",
    "df\n",
    "df1\n",
    "\n",
    "df_one_to_one = pd.merge(df, df1, validate = \"one_to_one\")\n",
    "df_one_to_one\n",
    "\n",
    "df_one_to_many = pd.merge(df, df1, validate = \"one_to_many\")\n",
    "df_one_to_many\n",
    "\n",
    "df_many_to_one = pd.merge(df, df1, validate = \"many_to_one\")\n",
    "df_many_to_one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick13\"></a>\n",
    "# Trick 13: Avoid the series of lists TRAP\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"A\":[1, 2, 3], \"B\":[[10, 20], [40, 50], [60, 70]]}\n",
    "df = pd.DataFrame(d)\n",
    "print(\"Notice that the column B has as values lists\")\n",
    "df\n",
    "print(\"Convert it to normal series\")\n",
    "df_ = df[\"B\"].apply(pd.Series)\n",
    "df_\n",
    "\n",
    "print(\"Join the 2 df\")\n",
    "pd.merge(df, df_, left_index = True, right_index = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick14\"></a>\n",
    "# Trick 14: Creating toy df (3 methods)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: from a dict\n",
    "pd.DataFrame({\"A\":[10 ,20], \"B\":[30, 40]})\n",
    "\n",
    "# Method 2: using numpy\n",
    "pd.DataFrame(np.random.rand(2, 3), columns = list(\"ABC\"))\n",
    "\n",
    "# Method 3: using pandas builtin functionalities\n",
    "pd.util.testing.makeMixedDataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick15\"></a>\n",
    "# Trick 15: Reshape a MultiIndex df (unstack())\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "print(\"Original df\")\n",
    "df.head()\n",
    "\n",
    "print(\"Groupby and create a MultiIndex df\")\n",
    "print(\"Notice we have a df with MultiIndex (Sex and Pclass)\")\n",
    "df.groupby([\"Sex\", \"Pclass\"])[\"Survived\"].mean().to_frame()\n",
    "\n",
    "print(\"Reshaping using unstack\")\n",
    "print(\"Now we can interact with it like with a normal df\")\n",
    "df.groupby([\"Sex\", \"Pclass\"])[\"Survived\"].mean().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick16\"></a>\n",
    "# Trick 16: Convert continuos values to categorical (cut())\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_sample_data()\n",
    "df[\"A\"] = df[\"A\"] + 5\n",
    "df.rename(columns = {\"A\":\"age\"}, inplace = True)\n",
    "df.sample(5)\n",
    "\n",
    "df[\"age_groups\"] = pd.cut(df[\"age\"], bins = [0, 18, 65, 99], labels = [\"kids\", \"adult\", \"elderly\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick17\"></a>\n",
    "# Trick 17: Select multiple rows and columns with loc\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_sample_data()\n",
    "print(\"Original df\")\n",
    "df\n",
    "\n",
    "print(\"Using a slice (inclusive)\")\n",
    "df.loc[0:4, \"A\":\"E\"]\n",
    "\n",
    "print(\"Using a list\")\n",
    "df.loc[[0,4], [\"A\",\"E\"]]\n",
    "\n",
    "print(\"Using a condition\")\n",
    "df.loc[df[\"A\"] > 10, [\"A\",\"E\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick18\"></a>\n",
    "# Trick 18: Read and write to a compressed file (csv.zip)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_sample_data()\n",
    "df.head()\n",
    "\n",
    "print(\"Writing data to a csv.zip file\")\n",
    "df.to_csv(\"trick18data.csv.zip\")\n",
    "\n",
    "print(\"Deleting df\")\n",
    "del df\n",
    "\n",
    "print(\"Importing data from a csv.zip file\")\n",
    "df = pd.read_csv(\"/kaggle/working/trick18data.csv.zip\", index_col=0)\n",
    "df.head()\n",
    "\n",
    "# other compression files supported .gz, .bz2, .xz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick19\"></a>\n",
    "# Trick 19: Show memory usage of a df and every column\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_sample_data_datetime().reset_index()\n",
    "df.columns = [\"date\", \"sales\", \"customers\"]\n",
    "df\n",
    "\n",
    "print(\"Show the global usage of memory of the df\")\n",
    "df.info(memory_usage = \"deep\")\n",
    "print()\n",
    "print(\"Show the usage of memory of every column\")\n",
    "df.memory_usage(deep = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick20\"></a>\n",
    "# Trick 20: Create a datetime columns from multiple columns\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"day\":[1, 2, 10 ,25, 12], \"month\":[1, 2, 4, 5, 6], \"year\":[2000, 2001, 2010, 2015, 2020]}\n",
    "df = pd.DataFrame(d)\n",
    "df[\"date\"] = pd.to_datetime(df[[\"day\", \"month\", \"year\"]])\n",
    "df\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick21\"></a>\n",
    "# Trick 21: Split a string column into multiple columns\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"name\":[\"John Artur Doe\", \"Jane Ann Smith\", \"Nico P\"], \"location\":[\"Los Angeles, CA\", \"Washington, DC\", \"Barcelona, Spain\"]}\n",
    "df = pd.DataFrame(d)\n",
    "df\n",
    "\n",
    "df[[\"first\", \"middle\", \"last\"]] = df[\"name\"].str.split(\" \", expand = True)\n",
    "df[\"city\"] = df[\"location\"].str.split(\",\", expand = True)[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick22\"></a>\n",
    "# Trick 22: Create DataFrames for testing\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Contains random values\")\n",
    "df1 = pd.util.testing.makeDataFrame() # contains random values\n",
    "df1\n",
    "print(\"Contains missing values\")\n",
    "df2 = pd.util.testing.makeMissingDataframe() # contains missing values\n",
    "df2\n",
    "print(\"Contains datetime values\")\n",
    "df3 = pd.util.testing.makeTimeDataFrame() # contains datetime values\n",
    "df3\n",
    "print(\"Contains mixed values\")\n",
    "df4 = pd.util.testing.makeMixedDataFrame() # contains mixed values\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick23\"></a>\n",
    "# Trick 23: Fill missing values in time series data (interpolate())\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"col1\":[100, 120 ,140, np.nan, 160], \"col2\":[9, 10, np.nan, 7.5, 6.5]}\n",
    "df = pd.DataFrame(d)\n",
    "df.index = pd.util.testing.makeDateIndex()[0:5]\n",
    "print(\"Original df\")\n",
    "df\n",
    "print(\"DataFrame after interpolate\")\n",
    "df.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick24\"></a>\n",
    "# Trick 24: Copy data from Excel into pandas quick (read_clipboard())\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will have to check this on your local machine\n",
    "# Useful for fast importing\n",
    "# Step 1: copy a table from excel sheet using ctrl + c (to the clipboard)\n",
    "# Step 2: run this command\n",
    "# df = pd.read_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick25\"></a>\n",
    "# Trick 25: 3 ways of renaming columns names\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_sample_data()\n",
    "df.head(2)\n",
    "\n",
    "# Solution 1\n",
    "df.rename({\"A\":\"col_1\", \"B\":\"col_2\"}, axis = \"columns\", inplace = True)\n",
    "df.head(2)\n",
    "\n",
    "# Solution 2\n",
    "df.columns = [\"col1\", \"col2\", \"col3\", \"col4\",\"col5\", \"col6\", \"col7\"] # list must be equal to the columns number\n",
    "df.head(2)\n",
    "\n",
    "# Solution 3\n",
    "df.columns = df.columns.str.title() # apply any string method to the columns names\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick26\"></a>\n",
    "# Trick 26: Formatting different columns of a df (using dictionaries)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_sample_data_datetime().reset_index()[:10]\n",
    "df.rename(columns = {\"index\":\"time\"}, inplace = True)\n",
    "df[\"sales_100\"] = df[\"sales\"]*100\n",
    "print(\"Original df\")\n",
    "df.head()\n",
    "\n",
    "# declare a formatting dict: individual for each column\n",
    "fd = {\"time\":\"{:%d/%m/%y}\", \"sales\":\"${:.2f}\", \"customers\":\"{:,}\"}\n",
    "df.style.format(fd)\n",
    "df\n",
    "\n",
    "# add some more formattin\n",
    "(df.style.format(fd)\n",
    " .hide_index()\n",
    " .highlight_min(\"sales\", color =\"red\")\n",
    " .highlight_max(\"sales\", color =\"green\")\n",
    " .background_gradient(subset = \"sales_100\", cmap =\"Blues\")\n",
    " .bar(\"customers\", color = \"lightblue\", align = \"zero\")\n",
    " .set_caption(\"A df with different stylings\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick27\"></a>\n",
    "# Trick 27: Aggregation over timeseries (resample)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_sample_data_datetime()\n",
    "\n",
    "print(\"Original df\")\n",
    "df\n",
    "print(\"Let's resample/groupby by month\")\n",
    "df.resample(\"M\")[\"sales\"].sum()\n",
    "\n",
    "print(\"Let's resample/groupby by day\")\n",
    "df.resample(\"D\")[\"sales\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick28\"></a>\n",
    "# Trick 28: Aggregating by multiple columns (using agg)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\")\n",
    "print(\"Original df\")\n",
    "df\n",
    "\n",
    "print(\"Groupby continent beer_servings\")\n",
    "df.groupby(\"continent\")[\"beer_servings\"].mean()\n",
    "\n",
    "print(\"Using agg to pass multiple functions\")\n",
    "df.groupby(\"continent\")[\"beer_servings\"].agg([\"mean\", \"count\"])\n",
    "\n",
    "print(\"Using describe over a groupby object\")\n",
    "df.groupby(\"continent\")[\"beer_servings\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick29\"></a>\n",
    "# Trick 29: Access numpy within pandas (without importing numpy as np)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas is built upon numpy, so we can acess all numpy functionality from pandas\n",
    "pd.np.random.rand(2, 3)\n",
    "pd.np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick30\"></a>\n",
    "# Trick 30: Pandas merge --> see where the columns are coming from (indicator = True)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_sample_data()\n",
    "df1 = df.copy(deep = True)\n",
    "df1 = df1.drop([0, 1, 2], axis = \"rows\") # drop some index just to see the example workings\n",
    "df.head()\n",
    "df1.head()\n",
    "\n",
    "pd.merge(df, df1, how = \"left\", indicator = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick31\"></a>\n",
    "# Trick 31: See all the columns of a big df\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4349bdffbe2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'^display.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# restore to default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_sample_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd.reset_option('^display.', silent=True) # restore to default\n",
    "\n",
    "df = generate_sample_data()\n",
    "df1 = df.copy(deep = True)\n",
    "df = df.append(df1)\n",
    "\n",
    "print(\"Imagine we have a big df where we can see all the columns ...\")\n",
    "df.T.head() # we are trasposing JUST TO CREATE A GIANT DF\n",
    "\n",
    "# Solution 1\n",
    "print(\"Solution 1 using pd.set_option display.max_columns\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "df.T.head()\n",
    "pd.reset_option('^display.', silent=True) # restore to default\n",
    "\n",
    "# Solution 2\n",
    "print(\"Another clever solution using Traspose\")\n",
    "df.T.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick32\"></a>\n",
    "# Trick 32: Filter a df with query and avoid intermediate variables\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_sample_data()[:10]\n",
    "df[\"A\"] = pd.Series([\"APP\", \"GOO\", \"APP\", \"GOO\", \"MIC\", \"MIC\", \"APP\", \"GOO\", \"MIC\", \"APP\"])\n",
    "df.rename(columns = {\"A\":\"stock\"}, inplace = True)\n",
    "print(\"Original df\")\n",
    "df\n",
    "\n",
    "print(\"Filter data using intermediate variables\")\n",
    "temp = df.groupby(\"stock\").mean()\n",
    "temp \n",
    "\n",
    "fv = temp[\"B\"].sort_values(ascending = False)[1] # filter by the second greates. This way every time we generate sample data we will have a result\n",
    "temp[temp[\"B\"] < fv]\n",
    "\n",
    "print(\"Filter using query\")\n",
    "df.groupby(\"stock\").mean().query(\"B < {}\".format(fv))\n",
    "df.groupby(\"stock\").mean().query(\"B < @fv\")\n",
    "df.groupby(\"stock\").mean().query(\"B < 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick33\"></a>\n",
    "# Trick 33: Pandas display options\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pd.describe_option() to see all\n",
    "# max_rows\n",
    "# max_columns\n",
    "# max_colwidth\n",
    "# precision\n",
    "# date_dayfirst\n",
    "# date_yearfirst\n",
    "\n",
    "df = generate_sample_data_datetime()[:10].reset_index()\n",
    "df[\"sales\"] = df[\"sales\"].astype(\"float\")\n",
    "df\n",
    "\n",
    "pd.set_option(\"display.max_rows\",5)\n",
    "pd.set_option(\"display.max_columns\",3)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.date_dayfirst', True)\n",
    "pd.describe_option()\n",
    "\n",
    "pd.reset_option('^display.', silent=True) # restore to default\n",
    "#pd.reset_option('display.width') # restore one by one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick34\"></a>\n",
    "# Trick 34: Explore a dataset with profiling\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "\n",
    "df = generate_sample_data()\n",
    "\n",
    "df\n",
    "\n",
    "print(\"Generating report with pandas profiling\")\n",
    "df.profile_report()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick35\"></a>\n",
    "# Trick 35: Query a column that has spaces in the name (using backticks)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"colum_without_space\":np.array([1, 2, 3, 4, 5, 6]), \"column with space\":np.array([1, 2, 3, 4, 5, 6])*2}\n",
    "df = pd.DataFrame(d)\n",
    "df\n",
    "\n",
    "print(\"Query a column without space\")\n",
    "df.query(\"colum_without_space > 4\")\n",
    "print(\"Query a column with space using backticks ``\")\n",
    "print(\"This is a backtick ``\")\n",
    "df.query(\"`column with space` > 8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick36\"></a>\n",
    "# Trick 36: Convert from UTC to another timezone\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(range(1552194000, 1552212001, 3600))\n",
    "s = pd.to_datetime(s, unit = \"s\")\n",
    "s\n",
    "\n",
    "# set timezome to current time zone (UTC)\n",
    "s = s.dt.tz_localize(\"UTC\")\n",
    "s\n",
    "\n",
    "# set timezome to another time zone (Chicago)\n",
    "s = s.dt.tz_convert(\"America/Chicago\")\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick37\"></a>\n",
    "# Trick 37: Pandas slicing loc and iloc (6 examples)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_sample_data()\n",
    "df\n",
    "\n",
    "# using loc --> labels\n",
    "df.loc[0, \"A\"]\n",
    "\n",
    "# using iloc --> position\n",
    "df.iloc[0, 0]\n",
    "\n",
    "# mixing labels and position with loc\n",
    "df.loc[0, df.columns[0]]\n",
    "\n",
    "# mixing labels and position with loc\n",
    "df.loc[df.index[0], \"A\"]\n",
    "\n",
    "# mixing labels and position with iloc\n",
    "df.iloc[0, df.columns.get_loc(\"A\")]\n",
    "\n",
    "# mixing labels and position with iloc\n",
    "df.iloc[df.index.get_loc(0), 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick38\"></a>\n",
    "# Trick 38: Pandas datetime (lot's of examples)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_sample_data_datetime().reset_index()\n",
    "df = df.sample(500)\n",
    "df[\"Year\"] = df[\"index\"].dt.year\n",
    "df[\"Month\"] = df[\"index\"].dt.month\n",
    "df[\"Day\"] = df[\"index\"].dt.day\n",
    "df[\"Hour\"] = df[\"index\"].dt.hour\n",
    "df[\"Minute\"] = df[\"index\"].dt.minute\n",
    "df[\"Second\"] = df[\"index\"].dt.second\n",
    "df[\"Nanosecond\"] = df[\"index\"].dt.nanosecond\n",
    "df[\"Date\"] = df[\"index\"].dt.date\n",
    "df[\"Time\"] = df[\"index\"].dt.time\n",
    "df[\"Time_Time_Zone\"] = df[\"index\"].dt.timetz\n",
    "df[\"Day_Of_Year\"] = df[\"index\"].dt.dayofyear\n",
    "df[\"Week_Of_Year\"] = df[\"index\"].dt.weekofyear\n",
    "df[\"Week\"] = df[\"index\"].dt.week\n",
    "df[\"Day_Of_week\"] = df[\"index\"].dt.dayofweek\n",
    "df[\"Week_Day\"] = df[\"index\"].dt.weekday\n",
    "df[\"Week_Day_Name\"] = df[\"index\"].dt.weekday_name\n",
    "df[\"Quarter\"] = df[\"index\"].dt.quarter\n",
    "df[\"Days_In_Month\"] = df[\"index\"].dt.days_in_month\n",
    "df[\"Is_Month_Start\"] = df[\"index\"].dt.is_month_start\n",
    "df[\"Is_Month_End\"] = df[\"index\"].dt.is_month_end\n",
    "df[\"Is_Quarter_Start\"] = df[\"index\"].dt.is_quarter_start\n",
    "df[\"Is_Quarter_End\"] = df[\"index\"].dt.is_quarter_end\n",
    "df[\"Is_Leap_Year\"] = df[\"index\"].dt.is_leap_year\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick39\"></a>\n",
    "# Trick 39: One hot encoding (get_dummies())\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/titanic/train.csv\", usecols = [2, 4, 5, 11], nrows = 10)\n",
    "df\n",
    "\n",
    "pd.get_dummies(df) # Notice that we can eliminate one column of each since this information is contained in the others\n",
    "\n",
    "pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick40\"></a>\n",
    "# Trick 40: Style you df fast with hide_index() and set_caption()\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_sample_data()\n",
    "print(\"Original df\")\n",
    "df\n",
    "\n",
    "df.style.hide_index().set_caption(\"Styled df with no index and a caption\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick41\"></a>\n",
    "# Trick 41: Ordered categories (from pandas.api.types import CategoricalDtypee)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "d = {\"ID\":[100, 101, 102, 103], \"quality\":[\"bad\", \"very good\", \"good\", \"excellent\"]}\n",
    "df = pd.DataFrame(d)\n",
    "df\n",
    "\n",
    "print(\"Let's create our own categorical order.\")\n",
    "cat_type = CategoricalDtype([\"bad\", \"good\", \"very good\", \"excellent\"], ordered = True)\n",
    "df[\"quality\"] = df[\"quality\"].astype(cat_type)\n",
    "df\n",
    "\n",
    "print(\"Now we can use logical sorting.\")\n",
    "df = df.sort_values(\"quality\", ascending = True)\n",
    "df\n",
    "\n",
    "print(\"We can also filter this as if they are numbers. AMAZING.\")\n",
    "df[df[\"quality\"] > \"bad\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick42\"></a>\n",
    "# Trick 42: New aggregation function --> last()\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"patient\":[1, 2, 3, 1, 1, 2], \"visit\":[2015, 2016, 2014, 2016, 2017, 2020]}\n",
    "df = pd.DataFrame(d)\n",
    "df.sort_values(\"visit\")\n",
    "\n",
    "print(\"Let's get the last visit for each patient\")\n",
    "df.groupby(\"patient\")[\"visit\"].last().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick43\"></a>\n",
    "# Trick 43: Create one row for each item in a list (explode) !!!duplicated Trick 47!!!\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice that we have a list of players for each team. Let's generate a row for each player.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f172b26aa5a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Notice that we have a list of players for each team. Let's generate a row for each player.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# It seems that this trick is duplicated, skip to the next one\n",
    "# I decided to keep in, so in the future there will be no confusion if you consult the original material\n",
    "# and this kernel\n",
    "d = {\"Team\":[\"FC Barcelona\", \"FC Real Madrid\"], \n",
    "    \"Players\":[[\"Ter Stegen\", \"Semedo\", \"Piqué\", \"Lenglet\", \"Alba\", \"Rakitic\", \"De Jong\", \"Sergi Roberto\", \"Messi\", \"Suárez\", \"Griezmann\"], \\\n",
    "               [\"Courtois\", \"Carvajal\", \"Varane\", \"Sergio Ramos\", \"Mendy\", \"Kroos\", \"Valverde\", \"Casemiro\", \"Isco\", \"Benzema\", \"Bale\"]]}\n",
    "\n",
    "print(\"Notice that we have a list of players for each team. Let's generate a row for each player.\")\n",
    "df = pd.DataFrame(d)\n",
    "df\n",
    "\n",
    "print(\"Using explode to generate new rows for each player.\")\n",
    "df1 = df.explode(\"Players\")\n",
    "df1\n",
    "\n",
    "print(\"Reverse this operation with groupby and agg\")\n",
    "df[\"Imploded\"] = df1.groupby(df1.index)[\"Players\"].agg(list)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick44\"></a>\n",
    "# Trick 44: Use a local variable within a query in pandas (using @)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_sample_data()\n",
    "df\n",
    "\n",
    "# create a local variable mean\n",
    "mean = df[\"A\"].mean()\n",
    "\n",
    "# now let's use in inside a query of pandas using @\n",
    "df.query(\"A > @mean\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick45\"></a>\n",
    "# Trick 45: Create rows for values separated by commas in a cell (assing and explode)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"Team\":[\"FC Barcelona\", \"FC Real Madrid\"], \n",
    "    \"Players\":[\"Ter Stegen, Semedo, Piqué, Lenglet, Alba, Rakitic, De Jong, Sergi Roberto, Messi, Suárez, Griezmann\",\n",
    "               \"Courtois, Carvajal, Varane, Sergio Ramos, Mendy, Kroos, Valverde, Casemiro, Isco, Benzema, Bale\"]}\n",
    "\n",
    "print(\"Notice that we have a list of players for each team separated by commas. Let's generate a row for each player.\")\n",
    "df = pd.DataFrame(d)\n",
    "df\n",
    "\n",
    "print(\"Notice that we have converted to something similar seen in example 47.\")\n",
    "df.assign(Players = df[\"Players\"].str.split(\",\"))\n",
    "\n",
    "print(\"Now add explode and done.\")\n",
    "df.assign(Players = df[\"Players\"].str.split(\",\")).explode(\"Players\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick46\"></a>\n",
    "# Trick 46: Store NaN in an integer type with Int64 (not int64)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Default series\")\n",
    "ser1 = pd.Series([10, 20])\n",
    "ser1\n",
    "\n",
    "print(\"Let's add a NaN to an int64 series\")\n",
    "ser1 = pd.Series([10, 20, np.nan])\n",
    "ser1 # Notice it has been converted to float64\n",
    "\n",
    "print(\"But if we use Int64 than everything will work\")\n",
    "ser1 = pd.Series([10, 20, np.nan], dtype = \"Int64\")\n",
    "ser1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick47\"></a>\n",
    "# Trick 47: Create one row for each item in a list (explode)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"Team\":[\"FC Barcelona\", \"FC Real Madrid\"], \n",
    "    \"Players\":[[\"Ter Stegen\", \"Semedo\", \"Piqué\", \"Lenglet\", \"Alba\", \"Rakitic\", \"De Jong\", \"Sergi Roberto\", \"Messi\", \"Suárez\", \"Griezmann\"], \\\n",
    "               [\"Courtois\", \"Carvajal\", \"Varane\", \"Sergio Ramos\", \"Mendy\", \"Kroos\", \"Valverde\", \"Casemiro\", \"Isco\", \"Benzema\", \"Bale\"]]}\n",
    "\n",
    "print(\"Notice that we have a list of players for each team. Let's generate a row for each player.\")\n",
    "df = pd.DataFrame(d)\n",
    "df\n",
    "\n",
    "print(\"Using explode to generate new rows for each player.\")\n",
    "df1 = df.explode(\"Players\")\n",
    "df1\n",
    "\n",
    "print(\"Reverse this operation with groupby and agg\")\n",
    "df[\"Imploded\"] = df1.groupby(df1.index)[\"Players\"].agg(list)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick48\"></a>\n",
    "# Trick 48: Useful parameters when using pd.read_csv()\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\")\n",
    "df.head()\n",
    "df.dtypes\n",
    "\n",
    "# Let's import the country and beer_servings columns, convert them to string and float64 respectevly\n",
    "# Import only the first 5 rows and thread 0 as nans\n",
    "df = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\",\n",
    "                    usecols=[\"country\", \"beer_servings\"],\n",
    "                    dtype={\"country\":\"category\", \"beer_servings\":\"float64\"},\n",
    "                    nrows = 5,\n",
    "                    na_values = 0.0)\n",
    "df.head()\n",
    "df.dtypes\n",
    "\n",
    "# more about read_csv on https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick49\"></a>\n",
    "# Trick 49: Sampling with pandas (with replacement and weights)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"A\": [100, 200, 300, 400, 100], \"W\":[10, 5, 0, 3, 8]}\n",
    "df = pd.DataFrame(d)\n",
    "df\n",
    "\n",
    "# with replacement\n",
    "df.sample(n = 5, replace = True, random_state = 2)\n",
    "\n",
    "# adding weights\n",
    "df.sample(n = 5, replace = True, random_state = 2, weights = \"W\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick50\"></a>\n",
    "# Trick 50: Named aggregation with multiple columns passing tupples (new in pandas 0.25)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "\n",
    "# Typical groupby\n",
    "print(\"Problem: MultiIndex\")\n",
    "df.groupby(\"Pclass\").agg({\"Age\":[\"mean\", \"max\"], \"Survived\": \"mean\"})\n",
    "\n",
    "# Please note that this has been covered in 86 and 86 bis.\n",
    "# This is just one more way to do it.\n",
    "print(\"Named aggregation\")\n",
    "df.groupby(\"Pclass\").agg(avg_age = (\"Age\", \"mean\"),\n",
    "                        max_age = (\"Age\", \"max\"), \n",
    "                        survival_rate = (\"Survived\", \"mean\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick51\"></a>\n",
    "# Trick 51: Concatenate 2 column strings\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_files()\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "\n",
    "# Solution 1: using str.cat \n",
    "df[\"Name\"].str.cat(df[\"Sex\"], sep = \", \").head()\n",
    "\n",
    "# using + sign\n",
    "df[\"Name\"] + \", \" + df[\"Sex\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick52\"></a>\n",
    "# Trick 52: Making plots with pandas\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_sample_data()\n",
    "\n",
    "df.plot(kind = \"line\")\n",
    "df.plot(kind = \"bar\")\n",
    "df.plot(kind = \"barh\")\n",
    "df.plot(kind = \"hist\")\n",
    "df.plot(kind = \"box\")\n",
    "df.plot(kind = \"kde\")\n",
    "df.plot(kind = \"area\")\n",
    "\n",
    "# the following plots requiere x and y\n",
    "df.plot(x = \"A\", y = \"B\", kind = \"scatter\")\n",
    "df.plot(x = \"A\", y = \"B\", kind = \"hexbin\")\n",
    "df.plot(x = \"A\", y = \"B\", kind = \"pie\") # here you can pass only x but you need to add subplots = True\n",
    "\n",
    "# other plots are available through pd.plotting\n",
    "# more about plotting https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick53\"></a>\n",
    "# Trick 53: Shuffle rows of a df (df.sample())\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_sample_data()\n",
    "\n",
    "df.sample(frac = 0.5, random_state = 2)\n",
    "df.sample(frac = 0.5, random_state = 2).reset_index(drop = True) # reset index after shuffeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick54\"></a>\n",
    "# Trick 54: Calculate the difference between each row and the previous (diff())\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_sample_data()\n",
    "df[\"A_diff\"] = df[\"A\"].diff() # calculate the difference between 2 rows\n",
    "df[\"A_diff_pct\"] = df[\"A\"].pct_change()*100 # calculates the porcentual variation between 2 rows\n",
    "\n",
    "# add some style\n",
    "df.style.format({\"A_diff_pct\":'{:.2f}%'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick55\"></a>\n",
    "# Trick 55: Filtering a df with multiple criteria using reduce\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\")\n",
    "df\n",
    "\n",
    "print(\"Classical filter hard to read and mantain.\")\n",
    "df[(df[\"continent\"] == \"Europe\") & (df[\"beer_servings\"] > 150) & (df[\"wine_servings\"] > 50) & (df[\"spirit_servings\"] < 60)]\n",
    "\n",
    "print(\"You can split it across multiple lines to make it more readable. But it's still hard to read.\")\n",
    "df[\n",
    "    (df[\"continent\"] == \"Europe\") & \n",
    "    (df[\"beer_servings\"] > 150) & \n",
    "    (df[\"wine_servings\"] > 50) & \n",
    "    (df[\"spirit_servings\"] < 60)\n",
    "]\n",
    "\n",
    "print(\"Solution saving criteria as objects\")\n",
    "\n",
    "cr1 = df[\"continent\"] == \"Europe\"\n",
    "cr2 = df[\"beer_servings\"] > 150\n",
    "cr3 = df[\"wine_servings\"] > 50\n",
    "cr4 = df[\"spirit_servings\"] < 60\n",
    "\n",
    "df[cr1 & cr2 & cr3 & cr4]\n",
    "\n",
    "print(\"Solution using reduce\")\n",
    "from functools import reduce\n",
    "\n",
    "# creates our criteria usings lambda\n",
    "# lambda takes 2 parameters, x and y\n",
    "# reduce combines them & for every cr in the (cr1, cr2, cr3, cr4)\n",
    "criteria = reduce(lambda x, y: x & y, (cr1, cr2, cr3, cr4))\n",
    "df[criteria]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick56\"></a>\n",
    "# Trick 56: Apply a mappings or functions to the whole df (applymap)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"A\":[\"Male\", \"Female\", \"Female\", \"Male\"], \"B\":[\"x\", \"y\", \"z\", \"A\"], \"C\":[\"male\", \"female\", \"male\", \"female\"], \"D\":[1, 2, 3, 4]})\n",
    "df\n",
    "\n",
    "# first let's use applymap to convert to standarize the text\n",
    "df = df.applymap(lambda x: x.lower() if type(x) == str else x)\n",
    "\n",
    "mapping = {\"male\":0, \"female\":1}\n",
    "\n",
    "print(\"PROBLEM: Applies to the whole df but retruns None\")\n",
    "df.applymap(mapping.get)\n",
    "\n",
    "print(\"Get the correct result but you have to specify the colums. If you don't want to do this, check the next result\")\n",
    "df[[\"A\", \"C\"]].applymap(mapping.get)\n",
    "\n",
    "print(\"Condtional apply map: if can map --> map else return the same value\")\n",
    "df = df.applymap(lambda x: mapping[x] if x in mapping.keys() else x)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick57\"></a>\n",
    "# Trick 57: Accesing the groups of a groupby object (get_group())\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_files()\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/imdb-data/IMDB-Movie-Data.csv\")\n",
    "df\n",
    "\n",
    "gbdf = df.groupby(\"Genre\")\n",
    "gbdf.get_group(\"Horror\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick58\"></a>\n",
    "# Trick 58: Use header and skiprows to get rid of bad data or empty rows while importing\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have empty rows and bad data\n",
    "df = pd.read_csv(\"/kaggle/input/trick58data/trick58data.csv\")\n",
    "df\n",
    "\n",
    "# importing correct data\n",
    "df = pd.read_csv(\"/kaggle/input/trick58data/trick58data.csv\", header = 2, skiprows = [3,4])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick59\"></a>\n",
    "# Trick 59: Combine the output of an aggregation with the original df using transform\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"orderid\":[1, 1, 1, 2, 2, 3, 4, 5], \"item\":[10, 120, 130, 200, 300, 550, 12.3, 200]}\n",
    "df = pd.DataFrame(d)\n",
    "df\n",
    "\n",
    "print(\"This is the output we want to aggregate to the original df\")\n",
    "df.groupby(\"orderid\")[\"item\"].sum().to_frame()\n",
    "\n",
    "df[\"total_items_sold\"] = df.groupby(\"orderid\")[\"item\"].transform(sum)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick60\"></a>\n",
    "# Trick 60: Creating running totals with cumsum function\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"salesperson\":[\"Nico\", \"Carlos\", \"Juan\", \"Nico\", \"Nico\", \"Juan\", \"Maria\", \"Carlos\"], \"item\":[10, 120, 130, 200, 300, 550, 12.3, 200]}\n",
    "df = pd.DataFrame(d)\n",
    "df\n",
    "\n",
    "df[\"running_total\"] = df[\"item\"].cumsum()\n",
    "df[\"running_total_by_person\"] = df.groupby(\"salesperson\")[\"item\"].cumsum()\n",
    "df\n",
    "\n",
    "# other useful functions are cummax(), cummin(), cumprod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick61\"></a>\n",
    "# Trick 61: Reading JSON from the web into a df\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/justmarkham?tab=repositories\"\n",
    "\n",
    "# run it on your local machine\n",
    "# df = pd.read_json(url)\n",
    "# df = df[df[\"fork\"] == False]\n",
    "# df.shape\n",
    "# df.head()\n",
    "\n",
    "# lc = [\"name\", \"stargazers_count\", \"forks_count\"]\n",
    "# df[lc].sort_values(\"stargazers_count\", asending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick62\"></a>\n",
    "# Trick 62: Fixing \"SettingWithCopyWarning\" when changing columns using loc\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"gender\":[\"Male\", \"Female\", \"Female\", \"Male\"]})\n",
    "df\n",
    "\n",
    "# Getting this nasty warning\n",
    "df[df[\"gender\"] == \"Male\"][\"gender\"] = 1\n",
    "df[df[\"gender\"] == \"Female\"][\"gender\"] = 0\n",
    "\n",
    "\n",
    "print(\"Fix using loc\")\n",
    "df.loc[df[\"gender\"] == \"Male\", \"gender\"] = 1\n",
    "df.loc[df[\"gender\"] == \"Female\", \"gender\"] = 0\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick63\"></a>\n",
    "# Trick 63: Calculate running count with groups using cumcount() + 1\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"salesperson\":[\"Nico\", \"Carlos\", \"Juan\", \"Nico\", \"Nico\", \"Juan\", \"Maria\", \"Carlos\"], \"item\":[\"Car\", \"Truck\", \"Car\", \"Truck\", \"cAr\", \"Car\", \"Truck\", \"Moto\"]}\n",
    "df = pd.DataFrame(d)\n",
    "df\n",
    "\n",
    "# Fixing columns\n",
    "df[\"salesperson\"] = df[\"salesperson\"].str.title()\n",
    "df[\"item\"] = df[\"item\"].str.title()\n",
    "\n",
    "df[\"count_by_person\"] = df.groupby(\"salesperson\").cumcount() + 1\n",
    "df[\"count_by_item\"] = df.groupby(\"item\").cumcount() + 1\n",
    "df[\"count_by_both\"] = df.groupby([\"salesperson\",\"item\"]).cumcount() + 1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick64\"></a>\n",
    "# Trick 64: Fixing \"SettingWithCopyWarning\" when creating a new columns\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"gender\":[\"Male\", \"Female\", \"Female\", \"Male\"]})\n",
    "df\n",
    "\n",
    "# Getting this nasty warning\n",
    "males = df[df[\"gender\"] == \"Male\"]\n",
    "males[\"abbreviation\"] = \"M\"\n",
    "\n",
    "# Fixing the error\n",
    "print(\"Fixing the warning with print\")\n",
    "males = df[df[\"gender\"] == \"Male\"].copy()\n",
    "males[\"abbreviation\"] = \"M\"\n",
    "males"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick65\"></a>\n",
    "# Trick 65: Select columns using f-strings (new in pandas 3.6+)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\")\n",
    "df\n",
    "\n",
    "drink = \"wine\"\n",
    "\n",
    "# allows us to iterate fast over columns\n",
    "df[f'{drink}_servings'].to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick66\"></a>\n",
    "# Trick 66: Create a bunch of new columns using a for loop and f-strings df[f'{col}_new']\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "d = {\"state\":[\"ny\", \"CA\", \"Tx\", \"FI\"], \"country\":[\"USA\", \"usa\", \"UsA\", \"uSa\"], \"pop\":[1000000, 2000000, 30000, 40000]}\n",
    "df = pd.DataFrame(d)\n",
    "df\n",
    "\n",
    "int_types = [\"int64\"]\n",
    "# creating new columns\n",
    "for col in df.columns:\n",
    "    ctype = str(df[col].dtype)\n",
    "    if ctype in int_types:\n",
    "        df[f'{col}_millions'] = df[col]/1000000\n",
    "    elif ctype == \"object\":\n",
    "        df[f'{col}_new'] = df[col].str.upper()\n",
    "        # you can also drop the columns\n",
    "        df.drop(col, inplace = True, axis = \"columns\")\n",
    "        \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick67\"></a>\n",
    "# Trick 67: Create new columns or overwrite using assing and set a title for the df\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "print_files()\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\", usecols=[\"continent\", \"beer_servings\"])\n",
    "df.head()\n",
    "\n",
    "(df.assign(continent = df[\"continent\"].str.title(),\n",
    "           beer_ounces = df[\"beer_servings\"]*12,#                                     this will allow yo set a title\n",
    "           beer_galons = lambda df: df[\"beer_ounces\"]/128).query(\"beer_galons > 30\").style.set_caption(\"Average beer consumption\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick68\"></a>\n",
    "# Trick 68: Webscraping using read_html()\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will have to run this on you local machine\n",
    "#apple_stocks = pd.read_html(\"https://finance.yahoo.com/quote/AAPL/history?p=AAPL\")\n",
    "#pd.concat([apple_stocks[0], apple_stocks[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick69\"></a>\n",
    "# Trick 69: Check if 2 series are \"similar\"\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"A\":[1, 2, 3, 4,], \"B\":[1.0, 2.0, 3.0, 4.0], \"C\":[1.00000, 2.00000, 3.00000, 4.000003], \"D\":[1.0, 2.0, 3.0, 4.0], \"E\":[4.0, 2.0, 3.0, 1.0]}\n",
    "df = pd.DataFrame(d)\n",
    "df\n",
    "\n",
    "df[\"A\"].equals(df[\"B\"]) # they requiere identical datatypes\n",
    "df[\"B\"].equals(df[\"C\"])\n",
    "df[\"B\"].equals(df[\"D\"])\n",
    "df[\"B\"].equals(df[\"E\"]) # and the same order\n",
    "\n",
    "print(pd.testing.assert_series_equal(df[\"A\"], df[\"B\"], check_names=False, check_dtype=False)) # assertion passes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick70\"></a>\n",
    "# Trick 70: Print current version of pandas and it's dependencies\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.__version__)\n",
    "print(pd.show_versions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick71\"></a>\n",
    "# Trick 71: Read data from a PDF (tabula py)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will have to run on your local machine\n",
    "#from tabula import read_pdf\n",
    "# df = read_pdf(\"test.pdf\", pages = \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick72\"></a>\n",
    "# Trick 72: Convert continuos variable to categorical (cut and qcut)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/imdb-data/IMDB-Movie-Data.csv\")\n",
    "df.head()\n",
    "\n",
    "# Using cut you can specify the bin edges\n",
    "pd.cut(df[\"Metascore\"], bins = [0, 25, 50, 75, 99]).head()\n",
    "\n",
    "# Using qcut you can specify the number of bins and it fill generate of aproximate equal size\n",
    "pd.qcut(df[\"Metascore\"], q = 3).head()\n",
    "\n",
    "# cut and qcut accept label bin size\n",
    "pd.qcut(df[\"Metascore\"], q = 4, labels = [\"awful\", \"bad\", \"average\", \"good\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick73\"></a>\n",
    "# Trick 73: Remove a column and store it as a separate series\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/imdb-data/IMDB-Movie-Data.csv\")\n",
    "df.head()\n",
    "\n",
    "meta = df.pop(\"Metascore\").to_frame()\n",
    "df.head()\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick74\"></a>\n",
    "# Trick 74: Webscraping using read_html() and match parameter\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this on you local machine\n",
    "# url = \"https://es.wikipedia.org/wiki/Twitter\"\n",
    "# tables = pd.read_html(url)\n",
    "# len(tables)\n",
    "\n",
    "# matching_tables = pd.read_html(url, match = \"Followers\")\n",
    "# matching_tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick75\"></a>\n",
    "# Trick 75: Count the number of words in a pandas series\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/imdb-data/IMDB-Movie-Data.csv\", usecols=[\"Title\"])\n",
    "df[\"Words\"] = df[\"Title\"].str.count(\" \") + 1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick76\"></a>\n",
    "# Trick 76: Filter in pandas only the largest categories.\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/imdb-data/IMDB-Movie-Data.csv\")\n",
    "df.columns = map(str.lower, list(df.columns)) # convert headers to lower type\n",
    "df.shape\n",
    "# select top 3 genre\n",
    "top_genre = df[\"genre\"].value_counts().to_frame()[0:3].index\n",
    "\n",
    "# now let's filter the df with the top genre\n",
    "df_top = df[df[\"genre\"].isin(top_genre)]\n",
    "df_top\n",
    "df_top.shape\n",
    "df_top[\"genre\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick77\"></a>\n",
    "# Trick 77: Combine the small categories into a single category named \"Others\" (using where)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"genre\": [\"A\", \"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"C\", \"D\", \"E\", \"F\"]}\n",
    "df = pd.DataFrame(d)\n",
    "df[\"genre\"].value_counts()\n",
    "\n",
    "# Step 1: count the frequencies\n",
    "top_four = df[\"genre\"].value_counts().nlargest(4).index\n",
    "top_four\n",
    "\n",
    "# Step 2: update the df\n",
    "df_updated = df.where(df[\"genre\"].isin(top_four), other = \"Other\")\n",
    "df_updated[\"genre\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick78\"></a>\n",
    "# Trick 78: Keep track of where your data is coming when you are using multiple sources\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's generate some fake data\n",
    "df1 = generate_sample_data()\n",
    "df2 = generate_sample_data()\n",
    "df3 = generate_sample_data()\n",
    "# df1.head()\n",
    "# df2.head()\n",
    "# df3.head()\n",
    "df1.to_csv(\"trick78data1.csv\")\n",
    "df2.to_csv(\"trick78data2.csv\")\n",
    "df3.to_csv(\"trick78data3.csv\")\n",
    "\n",
    "# Step 1 generate list with the file name\n",
    "lf = []\n",
    "for _,_, files in os.walk(\"/kaggle/working/\"):\n",
    "    for f in files:\n",
    "        if \"trick78\" in f:\n",
    "            lf.append(f)\n",
    "            \n",
    "lf\n",
    "\n",
    "# You can use this on your local machine\n",
    "#from glob import glob\n",
    "#files = glob(\"trick78.csv\")\n",
    "\n",
    "# Step 2: assing create a new column named filename and the value is file\n",
    "# Other than this we are just concatinating the different dataframes\n",
    "df = pd.concat((pd.read_csv(file).assign(filename = file) for file in lf), ignore_index = True)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick79\"></a>\n",
    "# Trick 79: Count of rows that match a condition\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_sample_data()\n",
    "df.head()\n",
    "df.shape\n",
    "\n",
    "# absolute values\n",
    "(df[\"A\"] < 5).sum()\n",
    "print(\"In the columns A we have {} of rows that are below 5\".format((df[\"A\"] < 5).sum()))\n",
    "\n",
    "# percentage\n",
    "(df[\"A\"] < 5).mean()\n",
    "print(\"In the columns A the values that are below 5 represent {}%\".format((df[\"A\"] < 5).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick80\"></a>\n",
    "# Trick 80: Select multiple slices of columns from a df\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_sample_data().T\n",
    "cols_str = list(map(str, list(df.columns))) # so that we can do df[\"0\"] as string for the example\n",
    "df.columns = cols_str\n",
    "\n",
    "# Using pandas concatenation\n",
    "# if you are ever confused about axis = 1 or axis = 0, just put axis = \"columns\" or axis = \"rows\"\n",
    "pd.concat([df.loc[:, \"0\":\"2\"], df.loc[:, \"6\":\"10\"], df.loc[:, \"16\":\"19\"]], axis = \"columns\") # ------------------> here we are selecting columns converted to strings\n",
    "\n",
    "# Using lists\n",
    "# please ntoe that df.columns is a series with index, so we are using index to filter # -------------------------> here we are selecting the index of columns\n",
    "df[list(df.columns[0:3]) + list(df.columns[6:11]) + list(df.columns[16:20])]\n",
    "\n",
    "# Using numpy\n",
    "df.iloc[:, np.r_[0:3, 6:11, 16:20]] # probably the most beautiful solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick81\"></a>\n",
    "# Trick 81: Use apply(type) to see if you have mixed data types\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"customer\":[\"A\", \"B\", \"C\", \"D\", \"E\"], \"sales\":[100, \"100\", 50, 550.20, \"375.25\"]}\n",
    "df = pd.DataFrame(d)\n",
    "# everything seems  but this operation crashes df[\"sales\"].sum(). We have mixed data types\n",
    "df.dtypes\n",
    "df[\"sales\"].apply(type) # Wow we can see that we have int, str, floats inn one column\n",
    "df[\"sales\"].apply(type).value_counts() # See the number of each value\n",
    "\n",
    "df[\"sales\"] = df[\"sales\"].astype(float) # convert the data to float\n",
    "df[\"sales\"].sum()\n",
    "df[\"sales\"].apply(type).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick82\"></a>\n",
    "# Trick 82: Select data by label and position (chained iloc and loc)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\", index_col=\"country\")\n",
    "df.iloc[15:20, :].loc[:, \"beer_servings\":\"wine_servings\"]\n",
    "# iloc is used to filter the rows and loc the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick83\"></a>\n",
    "# Trick 83: Correct the data types while importing the df\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_files()\n",
    "df = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\")\n",
    "\n",
    "# Step 1: Let's the datetype of the columns\n",
    "col_types = df.dtypes.to_frame()\n",
    "col_types.rename({0:\"type\"}, inplace = True, axis = 1)\n",
    "col_types\n",
    "col_types.to_csv(\"trick83data.csv\")\n",
    "\n",
    "# Step 2: Let's import the previous data and convert it to a dictionary\n",
    "col_dict = pd.read_csv(\"trick83data.csv\", index_col = 0)[\"type\"].to_dict()\n",
    "\n",
    "# Step 3: Edit the dictionary with the correct data types\n",
    "print(\"Original dictionary\")\n",
    "col_dict\n",
    "col_dict[\"country\"] = \"category\"\n",
    "col_dict[\"continent\"] = \"category\"\n",
    "print(\"Modified dictionary\")\n",
    "col_dict\n",
    "\n",
    "# Step 4: Use the dictionary to import the data\n",
    "df = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\", dtype=col_dict)\n",
    "df.dtypes\n",
    "\n",
    "# Note: please note that you can use the dict from step1 and paste in like this\n",
    "df = pd.read_csv(\"/kaggle/input/drinks-by-country/drinksbycountry.csv\", \\\n",
    "dtype=\n",
    "{'country': 'category',\n",
    " 'beer_servings': 'int64',\n",
    " 'spirit_servings': 'int64',\n",
    " 'wine_servings': 'int64',\n",
    " 'total_litres_of_pure_alcohol': 'float64',\n",
    " 'continent': 'category'})\n",
    "# However, if you have many colums, this can be confusing\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick84\"></a>\n",
    "# Trick 84: Show fewer rows in a df\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This df occupies way too much space\")\n",
    "df = generate_sample_data()\n",
    "df\n",
    "\n",
    "print(\"using set_option to save some screen space\")\n",
    "pd.set_option(\"display.max_rows\", 6)\n",
    "df\n",
    "\n",
    "print(\"use reset_option all to reset to default\")\n",
    "pd.reset_option(\"all\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick85\"></a>\n",
    "# Trick 85: Convert one type of values to others\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some fast feature eng on the DF\n",
    "d = {\"gender\":[\"male\", \"female\", \"male\"], \"color\":[\"red\", \"green\", \"blue\"], \"age\":[25, 30, 15]}\n",
    "df = pd.DataFrame(d)\n",
    "df\n",
    "\n",
    "# Solution\n",
    "map_dict = {\"male\":\"M\", \"female\":\"F\"}\n",
    "df[\"gender_mapped\"] = df[\"gender\"].map(map_dict) # using dictionaries to map values\n",
    "df[\"color_factorized\"] = df[\"color\"].factorize()[0] # using factorize: returns a tuple of arrays (array([0, 1, 2]), Index(['red', 'green', 'blue'], dtype='object')) that's why we select [0]\n",
    "df[\"age_compared_boolean\"] = df[\"age\"] < 18 # return a True False boolean value\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick86\"></a>\n",
    "# Trick 86: Named aggregations - avoids multiindex\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_files()\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
    "df.head()\n",
    "\n",
    "# Problem 1\n",
    "print(\"The Problem relies on that we don't know the column name\")\n",
    "df.groupby(\"Pclass\")[\"Age\"].agg([\"mean\", \"max\"])\n",
    "\n",
    "# Problem 2\n",
    "print(\"The Problem relies on that we have multiindex\")\n",
    "df.groupby(\"Pclass\").agg({\"Age\":[\"mean\", \"max\"]})\n",
    "\n",
    "# Solution new in pandas 0.25 and higher\n",
    "print(\"Now we have solved the previous problems by specifyig the column final name we want.\")\n",
    "print(\"BUT IT ONLY WORKS WITH A COLUMN. TO THIS KIND OF OPERATIONS ON MULTIPLE COLUMNS CHECK THE NEXT CELL\")\n",
    "df.groupby(\"Pclass\")[\"Age\"].agg(age_mean = \"mean\", age_max = \"max\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick86bis\"></a>\n",
    "# Trick 86bis: Named aggregations on multiple columns- avoids multiindex\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_agg(x):\n",
    "    names = {\n",
    "        'age_mean': x['Age'].mean(),\n",
    "        'age_max':  x['Age'].max(),\n",
    "        'fare_mean': x['Fare'].mean(),\n",
    "        'fare_max': x['Fare'].max()\n",
    "    } # define you custom colum names and operations\n",
    "\n",
    "    return pd.Series(names, index=[ key for key in names.keys()]) # all the columns you create in the previous dictionary will be in this list comprehension\n",
    "\n",
    "df.groupby('Pclass').apply(my_agg)\n",
    "\n",
    "# reference\n",
    "# https://stackoverflow.com/questions/44635626/rename-result-columns-from-pandas-aggregation-futurewarning-using-a-dict-with\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick87\"></a>\n",
    "# Trick 87: Aggregate you datetime by by and filter weekends\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_sample_data_datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-55b58a699561>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_sample_data_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Step 1: resample by D. Basically agregate by day and use to_frame() to convert it to frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_sample_data_datetime' is not defined"
     ]
    }
   ],
   "source": [
    "df = generate_sample_data_datetime()\n",
    "df.shape\n",
    "df.head()\n",
    "\n",
    "# Step 1: resample by D. Basically agregate by day and use to_frame() to convert it to frame\n",
    "daily_sales = df.resample(\"D\")[\"sales\"].sum().to_frame()\n",
    "daily_sales\n",
    "\n",
    "# Step 2: filter weekends\n",
    "weekends_sales = daily_sales[daily_sales.index.dayofweek.isin([5, 6])]\n",
    "weekends_sales\n",
    "\n",
    "'''\n",
    "dayofweek day\n",
    "0         Monday\n",
    "1         Tuesday\n",
    "2         Wednesday\n",
    "3         Thursday\n",
    "4         Friday\n",
    "5         Saturday\n",
    "6         Sunday\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick88\"></a>\n",
    "# Trick 88: Rearrange columns in a df\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_sample_data()\n",
    "df.head()\n",
    "\n",
    "# Solution 1\n",
    "df[[\"A\", \"C\", \"D\", \"F\", \"E\", \"G\", \"B\"]].head() # doesn't modify in place\n",
    "\n",
    "# Solution 2\n",
    "cols_to_move = [\"A\", \"G\", \"B\"]\n",
    "\n",
    "new_order = cols_to_move + [c for c in df.columns if c not in cols_to_move] # generate your new order\n",
    "df[new_order].head()\n",
    "\n",
    "# Solutin 3: using index\n",
    "cols = df.columns[[0, 5 , 3, 4, 2, 1, 6]] # df.columns returns a series with index, we use the list to iorder the index as we like --> this way we order the columns\n",
    "df[cols].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick89\"></a>\n",
    "# Trick 89: Split names into first and last name\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.Series([\"Geordi La Forge\", \"Deanna Troi\", \"Data\"]).to_frame()\n",
    "df.rename({0:\"names\"}, inplace = True, axis = 1)\n",
    "df\n",
    "#                              split on first space  \n",
    "df[\"first_name\"] = df[\"names\"].str.split(n = 1).str[0]\n",
    "df[\"last_name\"] = df[\"names\"].str.split(n = 1).str[1]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick90\"></a>\n",
    "# Trick 90: Moving columns to a specific location\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"A\":[15, 20], \"B\":[20, 25], \"C\":[30 ,40], \"D\":[50, 60]}\n",
    "df = pd.DataFrame(d)\n",
    "df\n",
    "\n",
    "# Using insert\n",
    "df.insert(3, \"C2\", df[\"C\"]*2)\n",
    "df\n",
    "\n",
    "# Other solution\n",
    "df[\"C3\"] = df[\"C\"]*3 # create a new columns, it will be at the end\n",
    "columns = df.columns.to_list() # create a list with all columns\n",
    "location = 4 # specify the location where you want your new column\n",
    "columns = columns[:location] + [\"C3\"] + columns[location:-1] # reaarange the list\n",
    "df = df[columns] # create te dataframe in with the order of columns you like\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick91\"></a>\n",
    "# Trick 91: Creating a time series dataset for testing\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "# Solution 1\n",
    "number_or_rows = 365*24 # hours in a year\n",
    "pd.util.testing.makeTimeDataFrame(number_or_rows, freq=\"H\")\n",
    "\n",
    "# Solution 2\n",
    "num_cols = 2\n",
    "cols = [\"sales\", \"customers\"]\n",
    "df = pd.DataFrame(np.random.randint(1, 20, size = (number_or_rows, num_cols)), columns=cols)\n",
    "df.index = pd.util.testing.makeDateIndex(number_or_rows, freq=\"H\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick92\"></a>\n",
    "# Trick 92: Clean Object column with mixed data using regex\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "d = {\"customer\": [\"A\", \"B\", \"C\", \"D\"], \"sales\":[1100, 950.75, \"$400\", \"$1250.35\"]}\n",
    "df = pd.DataFrame(d)\n",
    "df\n",
    "\n",
    "# Step 1: check the data types\n",
    "df[\"sales\"].apply(type)\n",
    "\n",
    "# Step 2: use regex\n",
    "df[\"sales\"] = df[\"sales\"].replace(\"[$,]\", \"\", regex = True).astype(\"float\")\n",
    "df\n",
    "df[\"sales\"].apply(type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick93\"></a>\n",
    "# Trick 93: Combine the small categories into a single category named \"Others\" (using frequencies)\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"genre\": [\"A\", \"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"C\", \"D\", \"E\", \"F\"]}\n",
    "df = pd.DataFrame(d)\n",
    "df\n",
    "\n",
    "# Step 1: count the frequencies\n",
    "frequencies = df[\"genre\"].value_counts(normalize = True)\n",
    "frequencies\n",
    "\n",
    "# Step 2: establish your threshold and filter the smaller categories\n",
    "threshold = 0.1\n",
    "small_categories = frequencies[frequencies < threshold].index\n",
    "small_categories\n",
    "\n",
    "# Step 3: replace the values\n",
    "df[\"genre\"] = df[\"genre\"].replace(small_categories, \"Other\")\n",
    "df[\"genre\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick94\"></a>\n",
    "# Trick 94: Save memory by fixing your date\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/titanic/train.csv\", usecols = [\"Pclass\", \"Sex\", \"Parch\", \"Cabin\"])\n",
    "df\n",
    "\n",
    "# let's see how much our df occupies in memory\n",
    "df.memory_usage(deep = True)\n",
    "\n",
    "# convert to smaller datatypes\n",
    "df = df.astype({\"Pclass\":\"int8\",\n",
    "                \"Sex\":\"category\", \n",
    "                \"Parch\": \"Sparse[int]\", # most values are 0\n",
    "                \"Cabin\":\"Sparse[str]\"}) # most values are NaN\n",
    "\n",
    "df.memory_usage(deep = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick95\"></a>\n",
    "# Trick 95: Count the missing values\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\\\n",
    "\"col1\": [2019, 2019, 2020],\n",
    "\"col2\": [350, 365, 1],\n",
    "\"col3\": [np.nan, 365, None]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "df\n",
    "\n",
    "# Solution 1\n",
    "df.isnull().sum().sum()\n",
    "\n",
    "# Solution 2\n",
    "df.isna().sum()\n",
    "\n",
    "# Solution 3\n",
    "df.isna().any()\n",
    "\n",
    "# Solution 4:\n",
    "df.isna().any(axis = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick96\"></a>\n",
    "# Trick 96: Interactive plots out of the box in pandas\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.__version__)\n",
    "# Pandas version 0.25 or higher requiered and you need hvplot\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"../input/drinks-by-country/drinksbycountry.csv\")\n",
    "df\n",
    "\n",
    "# this one is not interactve\n",
    "df.plot(kind = \"scatter\", x = \"spirit_servings\", y = \"wine_servings\")\n",
    "\n",
    "# run !pip install hvplot\n",
    "#pd.options.plotting.backend = \"hvplot\"\n",
    "#df.plot(kind = \"scatter\", x = \"spirit_servings\", y = \"wine_servings\", c = \"continent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick97\"></a>\n",
    "# Trick 97: Convert year and day of year into a single datetime column\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trick 97\n",
    "# Convert\n",
    "d = {\\\n",
    "\"year\": [2019, 2019, 2020],\n",
    "\"day_of_year\": [350, 365, 1]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "df\n",
    "\n",
    "# Step 1: create a combined column\n",
    "df[\"combined\"] = df[\"year\"]*1000 + df[\"day_of_year\"]\n",
    "df\n",
    "\n",
    "# Step 2: convert to datetime\n",
    "df[\"date\"] = pd.to_datetime(df[\"combined\"], format = \"%Y%j\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick98\"></a>\n",
    "# Trick 98: Convert a wide DF into a long one\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\\\n",
    "\"zip_code\": [12345, 56789, 101112, 131415],\n",
    "\"factory\": [100, 400, 500, 600],\n",
    "\"warehouse\": [200, 300, 400, 500],\n",
    "\"retail\": [1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "df\n",
    "\n",
    "# we have to reassing\n",
    "\n",
    "# location_type is generated automatically from the columns left after specifying id_vars (you can pass a list also)\n",
    "df = df.melt(id_vars = \"zip_code\", var_name = \"location_type\", value_name = \"distance\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick99\"></a>\n",
    "# Trick 99: How to avoid Unnamed: 0 columns\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\\\n",
    "\"zip_code\": [12345, 56789, 101112, 131415],\n",
    "\"factory\": [100, 400, 500, 600],\n",
    "\"warehouse\": [200, 300, 400, 500],\n",
    "\"retail\": [1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "df\n",
    "\n",
    "# save to csv\n",
    "df.to_csv(\"trick99data.csv\")\n",
    "\n",
    "df = pd.read_csv(\"trick99data.csv\")\n",
    "df\n",
    "# To avoid Unnamed: 0\n",
    "\n",
    "df = pd.read_csv(\"trick99data.csv\", index_col=0)\n",
    "# or when saving df = pd.read_csv(\"trick99data.csv\", index = False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"trick100\"></a>\n",
    "# Trick 100: Loading sample of big data\n",
    "[Go back to the Table of Contents](#table_of_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/us-accidents/US_Accidents_June20.csv\")\n",
    "print(\"The shape of the df is {}\".format(df.shape))\n",
    "\n",
    "del df\n",
    "\n",
    "df = pd.read_csv(\"../input/us-accidents/US_Accidents_June20.csv\", skiprows = lambda x: x>0 and np.random.rand() > 0.01)\n",
    "print(\"The shape of the df is {}. It has been reduced 10 times!\".format(df.shape))\n",
    "\n",
    "\n",
    "'''\n",
    "How it works:\n",
    "skiprows accepts a function that is evaluated against the integer index.\n",
    "x > 0 makes sure that the headers is not skipped\n",
    "np.random.rand() > 0.01 returns True 99% of the tie, thus skipping 99% of the time.\n",
    "Note that we are using skiprows\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's all, thanks a lot. I hope you learned a lot of pandas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
