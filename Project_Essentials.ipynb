{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "<pre></pre>\n",
    "<font size=+1>\n",
    "    \n",
    "1. [Import Data](#Import-Data)<pre></pre>\n",
    "2. [Merging Dataframes and Groupby](#Merging-Dataframes-and-Groupby)<pre></pre>\n",
    "3. [Imputing Data](#Imputing-Data)<pre></pre>\n",
    "4. [API Requests](#API-Requests)<pre></pre>\n",
    "5. [SQL Queries](#SQL-Queries)<pre></pre>\n",
    "6. [Logistic Regression Example](#Logistic-Regression-Example)<pre></pre>\n",
    "7. [Dictionaries Example](#Dictionaries-Example)<pre></pre>\n",
    "8. [Classes and OOP](#Classes-and-OOP)<pre></pre>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "\n",
    "[Go back to the Table of Contents](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages usually want to upload with display settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 5000)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This creates dataframe specifying type of .csv encoding (ISO-8859-1 in this case)\n",
    "### This also specifies the names for each dataframe column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Csv_File_Name.csv', encoding='Encoding_Type',  names = ['Index', 'Column'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check type of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_fips_sliced_df['Full FIPS'] = string_fips_sliced_df['Full FIPS'].astype(dtype = int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strip Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This removes non numerical values from strings\n",
    "#Cleaned strings are then assigned to float values\n",
    "\n",
    "import re\n",
    "string_money_df = string_money_df.applymap(lambda x: re.sub(r'[^a-zA-Z0-9 -]', '', str(x)))\n",
    "string_money_df_cleaned = string_money_df.astype(dtype=float)\n",
    "string_money_df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Column_Name'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This shows the percent missing values for each  varialble in a dataframe\n",
    "\n",
    "DF_Percent_Missing = DF_Final_Vars.isna().mean().round(4)\n",
    "\n",
    "#This shows the variables with highest missing percent missing values first\n",
    "\n",
    "DF_Percent_Missing.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows that contain missing values in a specific column\n",
    "\n",
    "adjusted_df = df['Column_With_Missing_Values'].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changes all cells named 'Cell_ Value' to null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace('Cell_Value' , np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Dataframes and Groupby\n",
    "\n",
    "[Go back to the Table of Contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine multiple dataframes into one dataframe with side by side columns\n",
    "\n",
    "Imputed_dataset = pd.concat([imputed_cat_df, imputed_int_df, imputed_numeric_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Two Dataframes\n",
    "\n",
    "#This is dataframe includes target variable and all explanatory variables\n",
    "df_merged = pd.merge(df1, df2,  how='left', left_on='GIDBG', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groupby aggregate on multiple variables\n",
    "\n",
    "#Aggregate vars of interest by merging column and chemical\n",
    "#This gives chemical count for unique latitude and longitudes\n",
    "\n",
    "unique_merging_df = vars_of_interest_df.groupby(['Merging_Column','30. CHEMICAL']).aggregate(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This shows all variables in a dataframe that have a column name from a list\n",
    "#Just another way of doing it\n",
    "\n",
    "DF_Final_Vars.columns[DF_Final_Vars.columns.isin(cat_var_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates new dataframe for all houses worth less than 1 million dollars\n",
    "\n",
    "df_Mill = df.loc[df['price'] < 1000000]\n",
    "df_Mill.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you have a list of column names you would like to keep (If there are many many variables)\n",
    "#This creates a dataframe of the variables of interest\n",
    "\n",
    "Final_DF = df[List_Of_Kept_Var_Names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing Data\n",
    "[Go back to the Table of Contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute categorical variables\n",
    "\n",
    "#This is to calculate median for strings\n",
    "#Scipy for calculating mode\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "#Loop\n",
    "#I'm Here is to show if loop breaks\n",
    "for i in range(0, len(cat_var_df.columns)):\n",
    "        print('im here:', cat_var_df.columns[i])\n",
    "        imputed_cat_df.iloc[:,i].replace(np.NaN, scipy.stats.mode(imputed_cat_df.iloc[:,i], axis=0, nan_policy='raise')[0][0], inplace=True)      \n",
    "#impute mode for categorical vars\n",
    "\n",
    "#check\n",
    "imputed_cat_df.isna().sum()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute median for integers\n",
    "imputed_int_df = int_var_df\n",
    "for i in range(0, len(int_var_df.columns)):\n",
    "        imputed_int_df.iloc[:,i].replace(np.NaN, imputed_int_df.iloc[:,i].median(), inplace=True)\n",
    "        \n",
    "#check\n",
    "imputed_int_df.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute mean for numerical vars\n",
    "imputed_numeric_df = numeric_var_df\n",
    "for i in range(0, len(numeric_var_df.columns)):\n",
    "        print('im here:', numeric_var_df.columns[i])\n",
    "        imputed_numeric_df.iloc[:,i].replace(np.NaN, imputed_numeric_df.iloc[:,i].mean(), inplace=True)\n",
    "        \n",
    "##Imputed numerical dataframe\n",
    "\n",
    "#check\n",
    "imputed_numeric_df.isna().sum()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Requests\n",
    "[Go back to the Table of Contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull request from an API example\n",
    "\n",
    "import requests\n",
    "\n",
    "url = 'https://geo.fcc.gov/api/census/block/find'\n",
    "parameters = {\"lat\": latitude_longitude_df['12. LATITUDE'][0], \"lon\": latitude_longitude_df['13. LONGITUDE'][0], 'showall':'false'}\n",
    "req = requests.get(url, parameters)\n",
    "\n",
    "print(req.status_code)\n",
    "print(req.headers)\n",
    "print(req.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'latitude_longitude_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ad3d1d91e2aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://geo.fcc.gov/api/census/block/find'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"lat\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlatitude_longitude_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'12. LATITUDE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lon\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlatitude_longitude_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'13. LONGITUDE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'showall'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'false'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'latitude_longitude_df' is not defined"
     ]
    }
   ],
   "source": [
    "#This loop Will pull requests for any set of latitudes and longitudes\n",
    "#Change the length of the loop to go through an entire dataframe\n",
    "#This loop saves a file every 5000 requests\n",
    "#File Names will be labeled like this'FIPs' + '_' + str(count) + '.csv'\n",
    "#Files are updated and overwritten every time the loop is run\n",
    "#If there is an error in the loop SAVE PROGRESS TO A DIFFERENT FILE NAME\n",
    "\n",
    "import requests\n",
    "import datetime\n",
    "\n",
    "latitude_list = []\n",
    "longitude_list = []\n",
    "fips_code_list = []\n",
    "timestamps_list = []\n",
    "count = 0 \n",
    "url = 'https://geo.fcc.gov/api/census/block/find'\n",
    "for i in range(0, 5000):\n",
    "    parameters = {\"lat\": latitude_longitude_df['12. LATITUDE'][i], \"lon\": latitude_longitude_df['13. LONGITUDE'][i], 'showall':'false'}\n",
    "    try:\n",
    "        response = requests.get(url, parameters)\n",
    "        data = response.json()        \n",
    "        latitude_list.append(latitude_longitude_df['12. LATITUDE'][i])\n",
    "        longitude_list.append(latitude_longitude_df['13. LONGITUDE'][i])\n",
    "        fips_code_list.append(data['results'][0]['block_fips'])\n",
    "        timestamps_list.append(datetime.datetime.utcnow())\n",
    "    except:\n",
    "        print('Error at index:', i)\n",
    "        fips_code_list.append('Error')\n",
    "    if ((len(fips_code_list) % 5000) == 0):\n",
    "        FIPs_API_df = pd.DataFrame({'Latitude': latitude_list, 'Longitude': longitude_list, 'FIPS': fips_code_list, 'API_Time': timestamps_list})\n",
    "        pd.DataFrame.to_csv(FIPs_API_df, 'FIPs' + '_' + str(count) + '.csv')\n",
    "        count += 1\n",
    "        \n",
    "FIPs_API_df = pd.DataFrame({'Latitude': latitude_list, 'Longitude': longitude_list, 'FIPS': fips_code_list, 'API_Time': timestamps_list})\n",
    "FIPs_API_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a dataframe pulling information from an api\n",
    "\n",
    "latitude_list2 = []\n",
    "longitude_list2 = []\n",
    "fips_code_list2 = []\n",
    "timestamps_list = []\n",
    "count = 0 \n",
    "url = 'https://geo.fcc.gov/api/census/block/find'\n",
    "for i in range(25000, 30000):\n",
    "    parameters = {\"lat\": latitude_longitude_df['12. LATITUDE'][i], \"lon\": latitude_longitude_df['13. LONGITUDE'][i], 'showall':'false'}\n",
    "    try:\n",
    "        response = requests.get(url, parameters)\n",
    "        data = response.json()        \n",
    "        latitude_list2.append(latitude_longitude_df['12. LATITUDE'][i])\n",
    "        longitude_list2.append(latitude_longitude_df['13. LONGITUDE'][i])\n",
    "        fips_code_list2.append(data['results'][0]['block_fips'])\n",
    "        timestamps_list.append(datetime.datetime.utcnow())\n",
    "    except:\n",
    "        print('Error at index:', i)\n",
    "        fips_code_list2.append('Error')\n",
    "    if ((len(fips_code_list2) % 5000) == 0):\n",
    "        FIPs_API_df = pd.DataFrame({'Latitude': latitude_list2, 'Longitude': longitude_list2, 'FIPS': fips_code_list2, 'API_Time': timestamps_list})\n",
    "        pd.DataFrame.to_csv(FIPs_API_df, 'FIPs1987Extra' + '_' + str(count) + '.csv')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Example of pulling information from SQL Database\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "class WeatherGetter(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.secret_key = \"d13ab59eaab2f300a54654adcc38d3b4\"\n",
    "        self.berlin_lat = \"52.5200\"\n",
    "        self.berlin_long = \"13.4050\"\n",
    "        self.url_base = \"https://api.darksky.net/forecast\"\n",
    "        self.exclude = 'currently,flags,minutely,hourly,alerts'\n",
    "        \n",
    "    def get_weather_data_for_date(self, datetime_string, verbose=True):\n",
    "        \n",
    "        year, month, day = self.format_datetime(datetime_string)\n",
    "        \n",
    "        datetime = \"{}-{}-{}T12:00:00\".format(year, month, day)\n",
    "        full_url = \"{}/{}/{},{},{}?exclude={}\".format(self.url_base, self.secret_key, \n",
    "                                                     self.berlin_lat, self.berlin_long, \n",
    "                                                     datetime, self.exclude)\n",
    "        response = requests.get(full_url)\n",
    "        if response.status_code == 200:\n",
    "            if verbose:\n",
    "                print(response.status_code)\n",
    "            return response\n",
    "        else: \n",
    "            raise ValueError(\"Error getting data from DarkSky API: Response Code {}\".format(response.status_code))\n",
    "            \n",
    "    def was_raining(self, response, verbose=True):\n",
    "        data = json.loads(response.text)\n",
    "        daily = data['daily']\n",
    "        data =  daily['data']\n",
    "        data = data[0]\n",
    "        if data['icon'] == 'rain':\n",
    "            if verbose:\n",
    "                print(data['icon'])\n",
    "            return True\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(data['icon'])\n",
    "            return False\n",
    "    \n",
    "    def format_datetime(self, datetime_string):\n",
    "        year = datetime_string[:4]\n",
    "        month = datetime_string[5:7]\n",
    "        day = datetime_string[8:]\n",
    "        \n",
    "        return year, month, day\n",
    "    \n",
    "    def did_rain_on_date(self, datetime_string):\n",
    "        \n",
    "        response = self.get_weather_data_for_date(datetime_string, verbose=False)\n",
    "        did_rain = self.was_raining(response, verbose=False)\n",
    "        \n",
    "        return did_rain\n",
    "    \n",
    "    def get_weather_for_all_dates(self, dates_list):\n",
    "        \"\"\"Expects input of dates in yyyy-mm-dd format\n",
    "        \n",
    "        Returns a dictionary where each date is the key. Rain days have a value of True, all others are False\"\"\"\n",
    "        \n",
    "        weather_dict = {}\n",
    "        \n",
    "        for date in dates_list:\n",
    "            weather_dict[date] = self.did_rain_on_date(date)\n",
    "        \n",
    "        return weather_dict\n",
    "    \n",
    "wg = WeatherGetter()\n",
    "wg.did_rain_on_date('2019-01-03')\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "conn = sqlite3.connect('''database.sqlite''')\n",
    "cur = conn.cursor()\n",
    "cur.execute('''select * from matches where season = 2011''')\n",
    "\n",
    "matches = pd.DataFrame(cur.fetchall())\n",
    "matches.columns = [i[0] for i in cur.description]\n",
    "matches.head()\n",
    "# Get number of unique dates for 2011 season, so that we don't have to repeat API calls for the same dates\n",
    "unique_dates = matches.Date.unique()\n",
    "print(\"# of Unique Game Dates in 2011 Season: {}\".format(len(unique_dates)))\n",
    "# Get rain status for each unique date in 2011 season\n",
    "rain_dates = wg.get_weather_for_all_dates(unique_dates)\n",
    "rain_dates\n",
    "# Create boolean column called 'Rain_Game' for the matches dataframe using the dictionary of values. \n",
    "rain_game = []\n",
    "for date in matches.Date:\n",
    "    rain_game.append(rain_dates[date])\n",
    "\n",
    "matches['Rain_Game'] = rain_game\n",
    "matches\n",
    "## Get all unique teams, and then create a basic data dictionary for each.\n",
    "## These values will be updated as we go through each match in the matches table. \n",
    "\n",
    "all_teams = matches['HomeTeam'].unique()\n",
    "print(\"# of Unique Teams: {}\".format(len(all_teams)))\n",
    "teams_data = {}\n",
    "for team in all_teams:\n",
    "    data = {'total_matches_2011': 0, \n",
    "           'total_wins_2011': 0,\n",
    "           'total_losses_2011': 0,\n",
    "           'rain_wins_2011': 0,\n",
    "           'rain_losses_2011': 0,\n",
    "           'total_goals_2011': 0}\n",
    "    teams_data[team] = data\n",
    "print(len(teams_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Queries\n",
    "[Go back to the Table of Contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL\n",
    "#Your code here; import necessary packages\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "#Your code here; create the database school.sqlite\n",
    "conn = sqlite3.Connection('school.sqlite')\n",
    "\n",
    "#Your code here\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"CREATE TABLE contactInfo (\n",
    "                                        userId INTEGER PRIMARY KEY,\n",
    "                                        firstName TEXT,\n",
    "                                        lastName TEXT,\n",
    "                                        role TEXT,\n",
    "                                        telephone INTEGER,\n",
    "                                        street TEXT,\n",
    "                                        city TEXT,\n",
    "                                        state TEXT,\n",
    "                                        zipcode TEXT\n",
    "                                        );\n",
    "            \"\"\")\n",
    "\n",
    "# Your code to iterate over the contact list and populate the contactInfo table here\n",
    "for contact in contacts:\n",
    "    firstName = contact['firstName']\n",
    "    lastName = contact['lastName']\n",
    "    role = contact['role']\n",
    "    telephone  = contact['telephone ']\n",
    "    street = contact['street']\n",
    "    city = contact['city']\n",
    "    state = contact['state']\n",
    "    zipcode  = contact['zipcode ']\n",
    "    cur.execute(\"\"\"INSERT INTO contactInfo (firstName, lastName, role, telephone, street, city, state, zipcode) \n",
    "                  VALUES ('{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}');\n",
    "                \"\"\".format(firstName, lastName, role, telephone, street, city, state, zipcode) )\n",
    "    \n",
    "Query the Table to Ensure it is populated\n",
    "\n",
    "# Your code here\n",
    "\n",
    "cur.execute(\"\"\"SELECT * FROM contactInfo;\"\"\")\n",
    "df = pd.DataFrame(cur.fetchall())\n",
    "df.columns = [x[0] for x in cur.description]\n",
    "df\n",
    "\n",
    "Commit Your Changes to the Database\n",
    "Persist your changes by committing them to the database.\n",
    "\n",
    "#Your code here\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL\n",
    "Remove Duplicate Entries\n",
    "An analyst just realized that there is a duplicate entry in the contactInfo table! Find and remove it.\n",
    "\n",
    "#Your code here; find the duplicate entry\n",
    "cur.execute(\"\"\"SELECT firstName, lastName, telephone, COUNT(*) \n",
    "               FROM contactInfo\n",
    "               GROUP BY 1,2,3\n",
    "               HAVING COUNT(*) > 1;\"\"\").fetchall()\n",
    "[('Jane', 'Evans', 3259909290, 2)]\n",
    "#Your code here; delete the duplicate entry\n",
    "cur.execute('''DELETE FROM contactInfo WHERE telephone = 3259909290;''')\n",
    "<sqlite3.Cursor at 0x112a06500>\n",
    "#Your code here; check that the duplicate entry was removed.\n",
    "cur.execute(\"\"\"SELECT firstName, lastName, telephone, COUNT(*) \n",
    "               FROM contactInfo\n",
    "               GROUP BY 1,2,3\n",
    "               HAVING COUNT(*) > 1;\"\"\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL\n",
    "Updating an Address\n",
    "Ed Lyman just moved to 2910 Simpson Avenue York, PA 17403. Update his address accordingly.\n",
    "\n",
    "#Your code here; update Ed's address\n",
    "cur.execute('''UPDATE contactInfo\n",
    "               SET street = \"2910 Simpson Avenue\",\n",
    "                   city = 'York',\n",
    "                   state = 'PA',\n",
    "                   zipcode = '17403'\n",
    "               WHERE firstName = \"Ed\" AND lastName = \"Lyman\";\n",
    "            ''')\n",
    "<sqlite3.Cursor at 0x112a06500>\n",
    "#Your code here; Query the database to ensure the change was made\n",
    "cur.execute(\"\"\"SELECT * FROM contactInfo;\"\"\")\n",
    "df = pd.DataFrame(cur.fetchall())\n",
    "df.columns = [x[0] for x in cur.description]\n",
    "df\n",
    "\n",
    "Once again, persist your changes by committing them to the database.\n",
    "\n",
    "#Your code here\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Example\n",
    "[Go back to the Table of Contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creates awesome correlation matrix using Seaborn\n",
    "# Needs matplotlib and sns\n",
    "\n",
    "corr = new_data.corr()\n",
    "plt.figure(figsize=(20,10))\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.set_context(\"paper\", font_scale=2)\n",
    "plt.title('Variables of Interest in our Analysis', fontsize=40)\n",
    "sns.heatmap(new_data.corr(),annot=True, linewidth=.5, cmap=\"coolwarm\", mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Great QQ plot for Regression Analysis\n",
    "\n",
    "#Residual Plot\n",
    "residuals = model.resid\n",
    "fig = sm.qqplot(residuals, stats.t, fit=True, line='45')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Residual vs. Prediction Plot for Regression using Seaborn\n",
    "\n",
    "sns.set(style='ticks')\n",
    "sns.regplot(Y_test, y=predictions, scatter_kws={'alpha':0.05});\n",
    "plt.title('Prediction Performance for House Price, < $1 million, 5-folds')\n",
    "plt.ylabel('Test Data')\n",
    "plt.xlabel('Trained Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Implementation\n",
    "\n",
    "#Data has been prepped\n",
    "#Begin fitting regression model\n",
    "import statsmodels.api as sm\n",
    "import sklearn.linear_model \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#create an instance and fit the model \n",
    "logmodel = LogisticRegression()\n",
    "sk_res = logmodel.fit(x_train, y_train)\n",
    "sk_predictions = logmodel.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, sk_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries Example\n",
    "[Go back to the Table of Contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the no. of pizzas you want to buy (max 3): 1\n",
      "Enter the toppings you would like in each pizza (max 4): 1\n",
      "\n",
      "Enter the flavor of Pizza No. 1: cheese\n",
      "Enter the flavor of Topping No. 1: cheese\n",
      "{'cheese': ['cheese']}\n"
     ]
    }
   ],
   "source": [
    "#Make a pizza input and dictionary\n",
    "p = int (input (\"Enter the no. of pizzas you want to buy (max 3): \"))\n",
    "t = int (input (\"Enter the toppings you would like in each pizza (max 4): \"))\n",
    "b = 1\n",
    "dict_pizza = {}\n",
    "for _ in range(p):\n",
    "    pizza = \"\"\n",
    "    pizza = str(input(f\"\\nEnter the flavor of Pizza No. {b}: \"))\n",
    "    dict_pizza[pizza] = []\n",
    "    b += 1\n",
    "    c = 1\n",
    "    for _ in range(t):    \n",
    "        topping = str(input(f\"Enter the flavor of Topping No. {c}: \"))\n",
    "        dict_pizza[pizza].append(topping)\n",
    "        c += 1\n",
    "        \n",
    "print(dict_pizza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome! Would you like to order ? (y/n): y\n",
      "Hi, welcome to our text based pizza ordering\n",
      "Available Pizzas:\n",
      "\n",
      "margarita, pollo, 4cheese, bolognese, vegetarian\n",
      "\n",
      "\n",
      "Available Topings:\n",
      "\n",
      "mushroom, onions, green pepper, extra cheese\n",
      "\n",
      "\n",
      "\n",
      "Please choose a pizza: taco\n",
      "I am sorry, we currently do not have taco\n",
      ".\n",
      "Available Pizzas:\n",
      "\n",
      "margarita, pollo, 4cheese, bolognese, vegetarian\n",
      "\n",
      "\n",
      "Available Topings:\n",
      "\n",
      "mushroom, onions, green pepper, extra cheese\n",
      "\n",
      "\n",
      "\n",
      "Please choose a pizza: margarita\n",
      "Please choose a topping: mushroom\n",
      "Final order: margarita with topping mushroom: \n",
      "Would you like to order again? (y/n): n\n",
      "Total:  6 $\n"
     ]
    }
   ],
   "source": [
    "#Final\n",
    "#Here is what your program would look like with all the changes\n",
    "\n",
    "import os\n",
    "\n",
    "available_pizzas = ['margarita', 'pollo', '4cheese', 'bolognese', 'vegetarian']\n",
    "available_toppings = ['mushroom', 'onions', 'green pepper', 'extra cheese']\n",
    "pizza_prices = {'margarita': 5, 'pollo': 7, '4cheese': 6, 'bolognese': 8, 'vegetarian': 6.5}\n",
    "topping_prices = {'mushroom':1, 'onions': 2, 'green pepper':3, 'extra cheese':4}\n",
    "\n",
    "def ShowMenu():\n",
    "    os.system('cls')\n",
    "    print(\"Available Pizzas:\\n\")\n",
    "    print(*available_pizzas,sep = ', ')\n",
    "    print(\"\\n\\nAvailable Topings:\\n\")\n",
    "    print(*available_toppings,sep = ', ')\n",
    "    print('\\n\\n')\n",
    "\n",
    "def TakeOrderInput():\n",
    "    os.system('cls')\n",
    "    print(\"Hi, welcome to our text based pizza ordering\")\n",
    "    ordering = True\n",
    "    while ordering:\n",
    "        os.system('cls')\n",
    "        ShowMenu()\n",
    "        pizza = input(\"Please choose a pizza: \")\n",
    "        if pizza not in available_pizzas:\n",
    "            print(f\"I am sorry, we currently do not have {pizza}\\n.\")\n",
    "            os.system('pause')\n",
    "            continue\n",
    "        topping = input(\"Please choose a topping: \")\n",
    "        if topping not in available_toppings:\n",
    "            print(f\"I am sorry, we currently do not have {topping}\\n.\")\n",
    "            os.system('pause')\n",
    "            continue\n",
    "\n",
    "        print(f\"Final order: {pizza} with topping {topping}: \")\n",
    "        ordering = False\n",
    "\n",
    "    return pizza,topping\n",
    "\n",
    "class Order:\n",
    "    def __init__(self):\n",
    "        taxes = 0 #You can add taxes\n",
    "        pizza,topping = TakeOrderInput()\n",
    "        self.type = pizza\n",
    "        self.topping = topping\n",
    "        self.PizzaPrice = pizza_prices[pizza]\n",
    "        self.ToppingPrice = topping_prices[topping]\n",
    "        self.Total = self.PizzaPrice + self.ToppingPrice\n",
    "\n",
    "\n",
    "choice = True\n",
    "orders = []\n",
    "orderchoice = input(\"Welcome! Would you like to order ? (y/n): \")\n",
    "if orderchoice == 'n':\n",
    "    print(\"Have a nice day!\")\n",
    "else:\n",
    "    while choice:\n",
    "        neworder = Order()\n",
    "        orders.append(neworder)\n",
    "        newchoice = input(\"Would you like to order again? (y/n): \")\n",
    "        if (newchoice) == 'n':\n",
    "            break\n",
    "\n",
    "total = 0\n",
    "for order in orders:\n",
    "    total+=order.Total\n",
    "\n",
    "print(\"Total: \",total, '$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes and OOP\n",
    "[Go back to the Table of Contents](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3\n",
      "3.5\n"
     ]
    }
   ],
   "source": [
    "class Student(object):\n",
    "    def __init__(self, name, age, gender, level, grades=None):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "        self.gender = gender\n",
    "        self.level = level\n",
    "        self.grades = grades or {}\n",
    "\n",
    "    def setGrade(self, course, grade):\n",
    "        self.grades[course] = grade\n",
    "\n",
    "    def getGrade(self, course):\n",
    "        return self.grades[course]\n",
    "\n",
    "    def getGPA(self):\n",
    "        return sum(self.grades.values())/len(self.grades)\n",
    "\n",
    "# Define some students\n",
    "john = Student(\"John\", 12, \"male\", 6, {\"math\":3.3})\n",
    "jane = Student(\"Jane\", 12, \"female\", 6, {\"math\":3.5})\n",
    "\n",
    "# Now we can get to the grades easily\n",
    "print(john.getGPA())\n",
    "print(jane.getGPA())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bird is ready\n",
      "Penguin is ready\n",
      "Penguin\n",
      "Swim faster\n",
      "Run faster\n"
     ]
    }
   ],
   "source": [
    "#Class Inheritance\n",
    "\n",
    "# parent class\n",
    "class Bird:\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"Bird is ready\")\n",
    "\n",
    "    def whoisThis(self):\n",
    "        print(\"Bird\")\n",
    "\n",
    "    def swim(self):\n",
    "        print(\"Swim faster\")\n",
    "\n",
    "# child class\n",
    "class Penguin(Bird):\n",
    "\n",
    "    def __init__(self):\n",
    "        # call super() function\n",
    "        super().__init__()\n",
    "        print(\"Penguin is ready\")\n",
    "\n",
    "    def whoisThis(self):\n",
    "        print(\"Penguin\")\n",
    "\n",
    "    def run(self):\n",
    "        print(\"Run faster\")\n",
    "\n",
    "peggy = Penguin()\n",
    "peggy.whoisThis()\n",
    "peggy.swim()\n",
    "peggy.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello  ::  7\n",
      "hi  ::  10\n",
      "there  ::  45\n",
      "at  ::  23\n",
      "this  ::  77\n",
      "**************\n",
      "Hello  ::  7\n",
      "hi  ::  10\n",
      "there  ::  45\n",
      "at  ::  23\n",
      "this  ::  77\n",
      "Dictionary View before modification : \n",
      "dict_items([('Hello', 7), ('hi', 10), ('there', 45), ('at', 23), ('this', 77)])\n",
      "Dictionary View after modification : \n",
      "dict_items([('Hello', 7), ('hi', 90), ('there', 45), ('at', 23), ('this', 77)])\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    '''\n",
    "    Creating Dictionaries with string as key and int as value\n",
    "    '''                                  \n",
    "    wordFrequency = {\n",
    "        \"Hello\" : 7,\n",
    "        \"hi\" : 10,\n",
    "        \"there\" : 45,\n",
    "        \"at\" : 23,\n",
    "        \"this\" : 77\n",
    "        }\n",
    "    '''\n",
    "    Iterate over the dictionary using for loop\n",
    "    '''\n",
    "    for key in wordFrequency:\n",
    "        value = wordFrequency[key]\n",
    "        print(key, \" :: \", value)\n",
    "    \n",
    "    print(\"**************\")    \n",
    "    \n",
    "    '''\n",
    "    Iterate over the dictionary using items()\n",
    "    '''    \n",
    "    for key , value in wordFrequency.items():\n",
    "        print(key, \" :: \", value)    \n",
    "    # Take a dictionary view \n",
    "    dictView =  wordFrequency.items()\n",
    "    \n",
    "    print(\"Dictionary View before modification : \", dictView, sep =\"\\n\")\n",
    "    \n",
    "    # Modify the dictionary\n",
    "    wordFrequency[\"hi\"] = 90\n",
    "    \n",
    "    print(\"Dictionary View after modification : \", dictView, sep =\"\\n\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
